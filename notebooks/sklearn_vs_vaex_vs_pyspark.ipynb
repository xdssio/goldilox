{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fleet-sapphire",
   "metadata": {},
   "source": [
    "# What I learned deploying the same pipeline with Skleran, PySpark and Vaex\n",
    "The main idea is to put to the test a complicated, real-world data science problem and solution.    \n",
    "We want to simulate real-world work.\n",
    "\n",
    "The first step is a \"quick & dirty\" POC where we figure stuff out, build features, model, and evaluate.    \n",
    "The second step is a pipeline for the solution in production.\n",
    "\n",
    "Pipeline steps:    \n",
    "\n",
    " * Cleaned *Cabin* values that have illegal values are unnecessary, but it is crucial to take cleaning data into account, as it significantly affects the pipeline.    \n",
    " * Calculating *FamilySize = Parch + SibSp + 1* (self)\n",
    " * Get the Initials from the name, and map them to either \"Mr\", \"Miss\", \"Mrs\" and \"Other\".\n",
    " * Calculate the mean *Age* for each Initial and use it to fill missing values for *Age*.\n",
    " * Create *AgeGroup* for each male/female and under/over the age of 15.\n",
    " * Bin *FamilySize* to the [0,1, 2, 5, 7, 100,1000] bins.\n",
    " * Encode *Embarked, Sex, FamilyBin, AgeGroup* with a label/one-hot encoder.\n",
    " * Use [LightGBM](https://lightgbm.readthedocs.io/en/latest/) (or Random Forest for PySpark) for modelling.\n",
    " * Add the survived/died probability in a consumable way.\n",
    " \n",
    "**Important notes**\n",
    "* Any calculated values should be done only the train data.\n",
    "* Quick-dirty things like \"dropna\" are used in POC, but not in the pipeline.\n",
    "* POC should still be correct.\n",
    "* Never filter data in production.\n",
    " \n",
    " \n",
    " \n",
    "* [Inpiried heavily  by this notebook](https://www.kaggle.com/bombatkarvivek/pyspark-ml-pipeline-with-titanic-dataset-eda).   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-church",
   "metadata": {},
   "source": [
    "# Pandas + Sklearn: Standard data science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-canadian",
   "metadata": {},
   "source": [
    "## POC\n",
    "This is a POC stage, works on my laptop...  fast and dirty.\n",
    "* This will not work on big data.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "noticed-universal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T15:28:21.155172Z",
     "start_time": "2021-09-17T15:28:20.915375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Initial</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>FamilyBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr</td>\n",
       "      <td>adult male</td>\n",
       "      <td>(1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>adult female</td>\n",
       "      <td>(1, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  FamilySize Initial      AgeGroup  \\\n",
       "0      0  A/5 21171   7.2500   NaN        S           2      Mr    adult male   \n",
       "1      0   PC 17599  71.2833   C85        C           2     Mrs  adult female   \n",
       "\n",
       "  FamilyBin  \n",
       "0    (1, 2]  \n",
       "1    (1, 2]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from icecream import ic \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "df = pd.read_csv('../datasets/titanic.csv')\n",
    "\n",
    "numeric_cols = ['PassengerId','Survived', 'Pclass', 'Age', 'SibSp','Parch','Ticket','Fare'] \n",
    "numeric_features = ['PassengerId','Pclass','Age', 'SibSp','Parch','Fare'] \n",
    "string_features = [ 'Embarked', 'Sex', 'FamilyBin', 'AgeGroup'] \n",
    "features = numeric_features\n",
    "\n",
    "\n",
    "df = df[df['Cabin'].str.contains(' ') != True]\n",
    "df['FamilySize'] = df['Parch'] + df['SibSp'] + 1\n",
    "df['Initial'] = df['Name'].str.extract(r'([A-Za-z]+)\\.')\n",
    "\n",
    "initials_map = {k:v for k,v in (zip(['Miss','Mr','Mrs','Mlle','Mme','Ms','Dr',\n",
    "                                               'Major','Lady','Countess',\n",
    "                                               'Jonkheer','Col','Rev',\n",
    "                                               'Capt','Sir','Don'],\n",
    "                                             ['Miss','Mr','Mrs','Miss','Miss','Miss',\n",
    "                                              'Mr','Mr','Mrs','Mrs',\n",
    "                                              'Other','Other','Other',\n",
    "                                              'Mr','Mr','Mr']))}\n",
    "df['Initial'] = df['Initial'].map(initials_map)\n",
    "train, test = train_test_split(df)\n",
    "\n",
    "means = train.groupby(['Initial'])['Age'].mean().to_dict() # this should be with train\n",
    "for initial, value in means.items():\n",
    "    df['Age'] = np.where((df['Age'].isnull()) & (df['Initial'].str.match(initial)),value, df['Age'])\n",
    "    \n",
    "df['AgeGroup'] = None\n",
    "df.loc[((df['Sex'] == 'male') & (df['Age'] <= 15)), 'AgeGroup'] = 'boy'\n",
    "df.loc[((df['Sex'] == 'female') & (df['Age'] <= 15)), 'AgeGroup'] = 'girl'\n",
    "df.loc[((df['Sex'] == 'male') & (df['Age'] > 15)), 'AgeGroup'] = 'adult male'\n",
    "df.loc[((df['Sex'] == 'female') & (df['Age'] > 15)), 'AgeGroup'] = 'adult female'\n",
    "\n",
    "df['FamilyBin'] = pd.cut(df['FamilySize'], [0,1, 2, 5, 7, 100,1000])\n",
    "df['FamilyBin'] = df['FamilyBin'].astype(str)\n",
    "\n",
    "\n",
    "train = df.loc[train.index].dropna(subset=string_features)\n",
    "test = df.loc[test.index].dropna(subset=string_features)\n",
    "\n",
    "encoders = {column: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan,\n",
    "                                     ).fit(train[column].values.reshape(-1,1)) for column in string_features}\n",
    "\n",
    "for column, encoder in encoders.items():\n",
    "    string_column = f\"le_{column}\"\n",
    "    train[string_column] = encoder.transform(train[column].values.reshape(-1,1)).reshape(-1)\n",
    "    test[string_column] = encoder.transform(test[column].values.reshape(-1,1)).reshape(-1)\n",
    "    features.append(string_column)\n",
    "    \n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "facial-utilization",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T15:28:24.167933Z",
     "start_time": "2021-09-17T15:28:23.875154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8101851851851852\n"
     ]
    }
   ],
   "source": [
    "# modelling\n",
    "model = LGBMClassifier()\n",
    "X = train[features]\n",
    "y = train[target]\n",
    "model.fit(X, y)\n",
    "        \n",
    "print(f\"accuracy: {accuracy_score(test[target],model.predict(test[features]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-terminology",
   "metadata": {},
   "source": [
    "## How NOT to go into production\n",
    "If you want to \"copy-paste\" this code - once for training, once with adjustments for inference, you are welcome to try...    \n",
    "In reality, a non-pipeline solution will crash in many unpredicted places - missing values, new values (for categorical features, for example), illegal values, for example.\n",
    "\n",
    "Implementing your model as code also means implementing a server technology like [FastAPI](https://fastapi.tiangolo.com/) (highly recommended), probably Docker, and master logging, error handling, deployments elements (environment variables, set-up a lambda docker vs Kubernetes, and timezones are to name a few) as part of the \"data-science\" side.\n",
    "\n",
    "It also means managing the pipeline's steps, feature-engineering, models parameters, features in server-side code, probably using docker image versioning, which forces every \"data-science\" change into a deployment cycle on the containers and server sides, as the code you save of the model must fit the code in inference time.\n",
    "\n",
    "If you let a DevOps/backend guys do it, you get much friction that hinders development; if you let the data scientist do it, you should give her a rise!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-cheat",
   "metadata": {},
   "source": [
    "### Not convinced? - here is how you would do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fitting-blocking",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T13:21:39.043798Z",
     "start_time": "2021-09-18T13:21:38.720555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7982062780269058\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from icecream import ic \n",
    "import cloudpickle\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class CustomModel():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.encoders = {}\n",
    "        self.means = {}\n",
    "        # this can be parameters too or read from a config file...\n",
    "        self.target = 'Survived'\n",
    "        self.numeric_cols = ['PassengerId','Survived', 'Pclass', 'Age', 'SibSp','Parch','Ticket','Fare'] \n",
    "        self.numeric_features = ['PassengerId','Pclass','Age', 'SibSp','Parch','Fare'] \n",
    "        self.string_features = [ 'Embarked', 'Sex', 'FamilyBin', 'AgeGroup'] \n",
    "        self.features = self.numeric_features.copy()\n",
    "        self.initials_map = {k:v for k,v in (zip(['Miss','Mr','Mrs','Mlle','Mme','Ms','Dr',\n",
    "                                                       'Major','Lady','Countess',\n",
    "                                                       'Jonkheer','Col','Rev',\n",
    "                                                       'Capt','Sir','Don'],\n",
    "                                                     ['Miss','Mr','Mrs','Miss','Miss','Miss',\n",
    "                                                      'Mr','Mr','Mrs','Mrs',\n",
    "                                                      'Other','Other','Other',\n",
    "                                                      'Mr','Mr','Mr']))}\n",
    "        self.accuracy = None        \n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_means(df, gb='Initial', column='Age'):\n",
    "        return df.groupby([gb])[column].mean().to_dict()\n",
    "        \n",
    "    def _encode_categoricals(self, df, stage='fit'):\n",
    "        if stage=='fit':\n",
    "            self.features = self.numeric_features.copy()\n",
    "            self.encoders = {column: OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan,\n",
    "                                         ).fit(df[column].fillna('').values.reshape(-1,1)) for column in self.string_features}\n",
    "        for column, encoder in self.encoders.items():\n",
    "            new_column = f\"le_{column}\"\n",
    "            df[new_column] = encoder.transform(df[column].fillna('').values.reshape(-1,1)).reshape(-1)\n",
    "            if new_column not in self.features:\n",
    "                self.features.append(new_column)\n",
    "        return df\n",
    "    \n",
    "    def _preprocess(self, df, stage='fit'):\n",
    "        if stage=='fit':\n",
    "            df = df[df['Cabin'].str.contains(' ') != True] # not do this in inference\n",
    "        df['FamilySize'] = df['Parch'] + df['SibSp'] + 1\n",
    "        df['Initial'] = df['Name'].str.extract(r'([A-Za-z]+)\\.')\n",
    "        df['Initial'] = df['Initial'].map(self.initials_map)\n",
    "        if stage=='fit':            \n",
    "            self.means = self._get_means(df)\n",
    "        for initial, value in self.means.items():\n",
    "            df['Age'] = np.where((df['Age'].isnull()) & (df['Initial'].str.match(initial)),value, df['Age'])\n",
    "                    \n",
    "        df['AgeGroup'] = None\n",
    "        df.loc[((df['Sex'] == 'male') & (df['Age'] <= 15)), 'AgeGroup'] = 'boy'\n",
    "        df.loc[((df['Sex'] == 'female') & (df['Age'] <= 15)), 'AgeGroup'] = 'girl'\n",
    "        df.loc[((df['Sex'] == 'male') & (df['Age'] > 15)), 'AgeGroup'] = 'adult male'\n",
    "        df.loc[((df['Sex'] == 'female') & (df['Age'] > 15)), 'AgeGroup'] = 'adult female'\n",
    "\n",
    "        df['FamilyBin'] = pd.cut(df['FamilySize'], [0,1, 2, 5, 7, 100,1000])\n",
    "        df['FamilyBin'] = df['FamilyBin'].astype(str)\n",
    "\n",
    "        df = self._encode_categoricals(df, stage=stage) \n",
    "        return df\n",
    "    \n",
    "    def _fit(self, df):\n",
    "        copy = self._preprocess(df, 'fit')\n",
    "        self.model = LGBMClassifier()\n",
    "        self.model.fit(copy[self.features], copy[self.target])\n",
    "        return self\n",
    "\n",
    "\n",
    "    def fit(self, path):\n",
    "        df = pd.read_csv(path)                \n",
    "        train, test = train_test_split(df)        \n",
    "        self._fit(train)\n",
    "        test = self.inference(test)\n",
    "        self.accuracy = accuracy_score(test[self.target], test['prediction'])\n",
    "        self._fit(df)\n",
    "        return self\n",
    "    \n",
    "    def inference(self, df):\n",
    "        df = self.infer(df)\n",
    "        copy = self._preprocess(df, 'inference')\n",
    "        copy['prediction'] = self.model.predict(copy[self.features])\n",
    "        copy['probabilities'] = [{'died':p[0],'survived':p[1]} for p in self.model.predict_proba(copy[self.features])]\n",
    "        copy['label'] = copy['prediction'].map({1:'survived',0:'died'})\n",
    "        return copy\n",
    "    \n",
    "    @classmethod\n",
    "    def infer(cls, df):\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            return df\n",
    "        if isinstance(df, dict):\n",
    "            return pd.DataFrame.from_records([df])\n",
    "        return pd.DataFrame(df)\n",
    "    \n",
    "    def save(self, path):\n",
    "        with open(path, 'wb') as outfile:\n",
    "            outfile.write(cloudpickle.dumps(self))\n",
    "            \n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        return pickle.loads(open(path,'rb').read())\n",
    "\n",
    "model = CustomModel().fit('../datasets/titanic.csv')\n",
    "model.save('../models/code.pkl')\n",
    "print(f\"Accuracy: {model.accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "better-produce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T13:21:39.498676Z",
     "start_time": "2021-09-18T13:21:39.426868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>Initial</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>FamilyBin</th>\n",
       "      <th>le_Embarked</th>\n",
       "      <th>le_Sex</th>\n",
       "      <th>le_FamilyBin</th>\n",
       "      <th>le_AgeGroup</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Christmann, Mr. Emil</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>343276</td>\n",
       "      <td>8.05</td>\n",
       "      <td>...</td>\n",
       "      <td>Mr</td>\n",
       "      <td>adult male</td>\n",
       "      <td>(0, 1]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'died': 0.9736046999325613, 'survived': 0.026...</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                  Name   Sex   Age  SibSp  \\\n",
       "0           91         0       3  Christmann, Mr. Emil  male  29.0      0   \n",
       "\n",
       "   Parch  Ticket  Fare  ... Initial    AgeGroup  FamilyBin le_Embarked le_Sex  \\\n",
       "0      0  343276  8.05  ...      Mr  adult male     (0, 1]         3.0    1.0   \n",
       "\n",
       "  le_FamilyBin  le_AgeGroup  prediction  \\\n",
       "0          0.0          2.0           0   \n",
       "\n",
       "                                       probabilities  label  \n",
       "0  {'died': 0.9736046999325613, 'survived': 0.026...   died  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"PassengerId\": 91, \n",
    "        \"Survived\": 0, \"Pclass\": 3, \n",
    "        \"Name\": \"Christmann, Mr. Emil\", \n",
    "        \"Sex\": \"male\", \n",
    "        \"Age\": 29.0, \n",
    "        \"SibSp\": 0, \n",
    "        \"Parch\": 0, \n",
    "        \"Ticket\": \"343276\", \"Fare\": 8.05, \n",
    "        \"Cabin\": \"A B\", # this make sure we don't filter\n",
    "        \"Embarked\": \"S\"}\n",
    "MyModel.load('../models/code.pkl').inference(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-schema",
   "metadata": {},
   "source": [
    "## Ok, show me a pipeline way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-courtesy",
   "metadata": {},
   "source": [
    "### Sklearn pipeline for deployment\n",
    "This is data engineering, the non-ops side of it.\n",
    "* This won't work on big data unless you use a big-ass machine (which is often a good solution).\n",
    "* This pipeline would work on a properly designed server, fitting/inference any pipeline or problem.\n",
    "* It is essential to adjust the pipeline not to filter data in inference time.\n",
    "* A standard sklearn pipeline cannot filter the data (because of the 'y' side) - we go around it by using only *fit* and *transform* without *predict*, and managing the target column in a custom transformer (LGBMTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "deluxe-cassette",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T13:26:27.250619Z",
     "start_time": "2021-09-18T13:26:26.855704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8071748878923767\n",
      "\n",
      "{\"PassengerId\": 566, \"Survived\": 0, \"Pclass\": 3, \"Name\": \"Davies, Mr. Alfred J\", \"Sex\": \"male\", \"Age\": 24.0, \"SibSp\": 2, \"Parch\": 0, \"Ticket\": \"A/4 48871\", \"Fare\": 24.15, \"Cabin\": NaN, \"Embarked\": \"S\", \"FamilySize\": 3, \"Initial\": \"Mr\", \"AgeGroup\": \"adult male\", \"FamilyBin\": \"(2, 5]\"}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import dump\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('../datasets/titanic.csv')\n",
    "train, test = train_test_split(df)\n",
    "\n",
    "target = 'Survived'\n",
    "fetures = list(train.columns)\n",
    "fetures.remove(target)\n",
    "\n",
    "\n",
    "dizip_initials = {k:v for k,v in (zip(['Mlle','Mme','Ms','Dr',\n",
    "                                               'Major','Lady','Countess',\n",
    "                                               'Jonkheer','Col','Rev',\n",
    "                                               'Capt','Sir','Don'],\n",
    "                                             ['Miss','Miss','Miss',\n",
    "                                              'Mr','Mr','Mrs','Mrs',\n",
    "                                              'Other','Other','Other',\n",
    "                                              'Mr','Mr','Mr']))}\n",
    "\n",
    "class PandasTransformer(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "     def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "class DropSome(PandasTransformer):\n",
    "    \n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "    \n",
    "    def transform(self, df, **transform_params):\n",
    "        return df[df[self.column].str.contains(' ')!=True]\n",
    "    \n",
    "    \n",
    "class FamilySizeTransformer(PandasTransformer):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        df['FamilySize'] = 1\n",
    "        for column in self.columns:\n",
    "            df['FamilySize'] = df['FamilySize']+df[column]\n",
    "        return df\n",
    "\n",
    "class InitialsTransformer(PandasTransformer):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "        self.initials_map = {k:v for k,v in (zip(['Miss','Mr','Mrs','Mlle','Mme','Ms','Dr',\n",
    "                                               'Major','Lady','Countess',\n",
    "                                               'Jonkheer','Col','Rev',\n",
    "                                               'Capt','Sir','Don'],\n",
    "                                             ['Miss','Mr','Mrs','Miss','Miss','Miss',\n",
    "                                              'Mr','Mr','Mrs','Mrs',\n",
    "                                              'Other','Other','Other',\n",
    "                                              'Mr','Mr','Mr']))}\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        df['Initial'] = df[self.column].str.extract(r'([A-Za-z]+)\\.')        \n",
    "        df['Initial'] = df['Initial'].map(self.initials_map)\n",
    "        return df   \n",
    "    \n",
    "\n",
    "class AgeImputer(PandasTransformer):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "        self.means = {}\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.means = X.groupby(['Initial'])['Age'].mean().round().astype(int).to_dict() \n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, df, **transform_params):\n",
    "        for initial, value in self.means.items():\n",
    "            df['Age'] = np.where((df['Age'].isnull()) & (df['Initial'].str.match(initial)),value, df['Age'])\n",
    "        return df   \n",
    "    \n",
    "class AgeGroupTransformer(PandasTransformer):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "    \n",
    "\n",
    "    def transform(self, df, **transform_params):\n",
    "        df['AgeGroup'] = None\n",
    "        df.loc[((df['Sex'] == 'male') & (df['Age'] <= 15)), 'AgeGroup'] = 'boy'\n",
    "        df.loc[((df['Sex'] == 'female') & (df['Age'] <= 15)), 'AgeGroup'] = 'girl'\n",
    "        df.loc[((df['Sex'] == 'male') & (df['Age'] > 15)), 'AgeGroup'] = 'adult male'\n",
    "        df.loc[((df['Sex'] == 'female') & (df['Age'] > 15)), 'AgeGroup'] = 'adult female'\n",
    "        return df\n",
    "  \n",
    "class BinTransformer(PandasTransformer):\n",
    "    def __init__(self, column,bins=None):\n",
    "        self.column = column\n",
    "        self.bins = bins or [0,1, 2, 5, 7, 100,1000]\n",
    "    \n",
    "\n",
    "    def transform(self, df, **transform_params):\n",
    "        df['FamilyBin'] = pd.cut(df[self.column], self.bins).astype(str)\n",
    "        return df\n",
    "\n",
    "\n",
    "class MultiColumnLabelEncoder(PandasTransformer):\n",
    "\n",
    "    def __init__(self, columns = None, prefix='le_', fillna_value=''):\n",
    "        self.columns = columns \n",
    "        self.encoders = {}\n",
    "        self.prefix = prefix\n",
    "        self.fillna_value = fillna_value\n",
    "        \n",
    "    def _add_prefix(self, col):\n",
    "        return f\"{self.prefix}{col}\"\n",
    "    \n",
    "    def preprocess_series(self, s):\n",
    "        return s.fillna(self.fillna_value).values.reshape(-1,1)\n",
    "        \n",
    "    def encode(self, column, X):\n",
    "        return self.encoders[column].transform(self.preprocess_series(X[column])).reshape(-1)\n",
    "        \n",
    "    def fit(self,X, y=None):\n",
    "        for column in self.columns:\n",
    "            le = OrdinalEncoder(handle_unknown='use_encoded_value',\n",
    "                                unknown_value=-1)\n",
    "            self.encoders[column] = le\n",
    "            le.fit(self.preprocess_series(X[column]))\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for column in self.columns:\n",
    "                output[self._add_prefix(column)] = self.encode(column, X)\n",
    "        return output\n",
    "\n",
    "        \n",
    "class FeatureSelector(PandasTransformer):\n",
    "\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "\n",
    "    def transform(self, df, **transform_params):        \n",
    "        return df[self.columns]\n",
    "\n",
    "class LGBMTransformer(PandasTransformer):\n",
    "\n",
    "    def __init__(self, target, features, output_column='prediction', **params):\n",
    "        self.features = features\n",
    "        self.params = params\n",
    "        self.model = None\n",
    "        self.target = target\n",
    "        self.output_column = output_column\n",
    "        \n",
    "    def fit(self,X, y):\n",
    "        self.model = LGBMClassifier(**self.params).fit(X[self.features], X[self.target])\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model is not trained\")\n",
    "        return self.model.predict(X[self.features])\n",
    "\n",
    "    def transform(self, df, **transform_params):        \n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model is not trained\")\n",
    "        missing_features = [feature for feature in self.features if feature not in df]\n",
    "        if len(missing_features)>0:\n",
    "            raise RuntimeError(f\"Features missing: {missing_features}\")\n",
    "        \n",
    "        df['prediction'] = self.model.predict(df[self.features])\n",
    "        probabilities = self.model.predict_proba(df[self.features])        \n",
    "        df['probabilities'] = [{'died':p[0],'survived':p[1]} for p in probabilities]\n",
    "        df['label'] = df['prediction'].map({1:'survived',0:'died'})\n",
    "        return df\n",
    "    \n",
    "\n",
    "class CleaningTransformer(PandasTransformer):   \n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def transform(self, df, **transform_params):        \n",
    "        return df[df[self.column].str.contains(' ')!=True]\n",
    "    \n",
    "    \n",
    "pipeline = Pipeline([\n",
    "    ('cleaning',CleaningTransformer('Cabin')),\n",
    "    ('FamilySizeTransformer', FamilySizeTransformer(['Parch','SibSp'])),\n",
    "    ('InitialsTransformer', InitialsTransformer('Name')),\n",
    "    ('AgeImputer', AgeImputer('Age')),\n",
    "    ('AgeGroupTransformer', AgeGroupTransformer('Age')),\n",
    "    ('BinTransformer', BinTransformer('FamilySize')),\n",
    "    ('MultiColumnLabelEncoder', MultiColumnLabelEncoder(columns=['Embarked', 'Sex', 'FamilyBin'])),\n",
    "    ('model', LGBMTransformer(target='Survived', features=['PassengerId','Pclass', 'Age', 'SibSp', \n",
    "                                        'Parch', 'Fare', 'le_Embarked','le_Sex', 'le_FamilyBin'],verbose=-1)),\n",
    "    ])\n",
    "\n",
    "\n",
    "# train\n",
    "target = 'Survived'\n",
    "fetures = list(train.columns)\n",
    "fetures.remove(target)\n",
    "\n",
    "X = train[fetures]\n",
    "y = train['Survived']\n",
    "\n",
    "\n",
    "pipeline = pipeline.fit(train)\n",
    "pipeline.steps = pipeline.steps[1:] # IMPORTANT - remove the filtering for inference\n",
    "print(f\"Accuracy: {accuracy_score(test[target], pipeline.predict(test))}\")\n",
    "\n",
    "# train on the entire dataset\n",
    "pipeline = pipeline.fit(df)\n",
    "\n",
    "# save a version for retrain when you have more data\n",
    "import cloudpickle # standard pickle and joblib won't work with custom transformers\n",
    "with open('../models/sklearn_fit.pkl', 'wb') as outfile:\n",
    "    outfile.write(cloudpickle.dumps(pipeline))\n",
    "    \n",
    "# save a version for inference\n",
    "pipeline.steps = pipeline.steps[1:] # IMPORTANT - remove the filtering for inference\n",
    "with open('../models/sklearn_inference.pkl', 'wb') as outfile:\n",
    "    outfile.write(cloudpickle.dumps(pipeline))\n",
    "\n",
    "\n",
    "print('')\n",
    "print(f\"{json.dumps(test.head(1).to_dict(orient='records')[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-fundamentals",
   "metadata": {},
   "source": [
    "* We would want to save the two pipelines - one for training with cleaning, one without for predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-arthritis",
   "metadata": {},
   "source": [
    "### Server\n",
    "In this form, a single server would work for every valid pipeline, changes of data and models should not effect the \"backend\" and \"DevOps\" sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "patient-military",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T12:56:27.072037Z",
     "start_time": "2021-09-18T12:56:27.001525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Initial</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>FamilyBin</th>\n",
       "      <th>le_Embarked</th>\n",
       "      <th>le_Sex</th>\n",
       "      <th>le_FamilyBin</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Christmann, Mr. Emil</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>343276</td>\n",
       "      <td>8.05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>adult male</td>\n",
       "      <td>(0, 1]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'died': 0.9228505083109125, 'survived': 0.077...</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                  Name   Sex   Age  SibSp  \\\n",
       "0           91         0       3  Christmann, Mr. Emil  male  29.0      0   \n",
       "\n",
       "   Parch  Ticket  Fare  ... FamilySize Initial    AgeGroup FamilyBin  \\\n",
       "0      0  343276  8.05  ...          1      Mr  adult male    (0, 1]   \n",
       "\n",
       "  le_Embarked le_Sex  le_FamilyBin  prediction  \\\n",
       "0         3.0    1.0           0.0           0   \n",
       "\n",
       "                                       probabilities  label  \n",
       "0  {'died': 0.9228505083109125, 'survived': 0.077...   died  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# server\n",
    "import pickle # here standard pickle does work (:\n",
    "import pandas as pd\n",
    "pipeline = pickle.loads(open('../models/sklearn_inference.pkl','rb').read())\n",
    "\n",
    "data = {\"PassengerId\": 91, \n",
    "        \"Survived\": 0, \"Pclass\": 3, \n",
    "        \"Name\": \"Christmann, Mr. Emil\", \n",
    "        \"Sex\": \"male\", \n",
    "        \"Age\": 29.0, \n",
    "        \"SibSp\": 0, \n",
    "        \"Parch\": 0, \n",
    "        \"Ticket\": \"343276\", \"Fare\": 8.05, \n",
    "        \"Cabin\": \"A B\", # this make sure we don't filter\n",
    "        \"Embarked\": \"S\"}\n",
    "data = pd.DataFrame.from_records([data])\n",
    "pd.DataFrame(pipeline.transform(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-dimension",
   "metadata": {},
   "source": [
    "# Vaex\n",
    "The POC stage is practically the same\n",
    "* This works with big data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "present-stable",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T13:30:52.832246Z",
     "start_time": "2021-09-18T13:30:49.834875Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from lakeml.vaex import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-concert",
   "metadata": {},
   "source": [
    "## POC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "forward-satellite",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T18:57:10.784823Z",
     "start_time": "2021-09-17T18:57:08.937723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8202247191011236\n"
     ]
    }
   ],
   "source": [
    "import vaex\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from vaex.ml.lightgbm import LightGBMModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from vaex.ml import LabelEncoder\n",
    "from icecream import ic \n",
    "from lakeml.vaex import Pipeline\n",
    "\n",
    "import pyarrow as pa\n",
    "import re\n",
    "\n",
    "\n",
    "df = vaex.open('../datasets/titanic.csv')\n",
    "train, test = df.split_random([0.8, 0.2])\n",
    "\n",
    "numeric_cols = ['PassengerId','Survived', 'Pclass', 'Age', 'SibSp','Parch','Ticket','Fare'] \n",
    "numeric_features = ['PassengerId','Pclass','Age', 'SibSp','Parch','Fare'] \n",
    "string_features = [ 'Embarked', 'Sex', 'FamilyBin'] \n",
    "features = numeric_features\n",
    "\n",
    "train = train[train['Cabin'].str.contains(' ') != True]\n",
    "train['FamilySize'] = train['Parch'] + train['SibSp'] + 1\n",
    "train['Name'] = train['Name'].fillna('Mr.')\n",
    "pattern = re.compile('([A-Za-z]+)\\.')\n",
    "\n",
    "train['Initial'] = train['Name'].str.extract_regex(r'(?P<initial>[A-Za-z]+)\\.').apply(lambda x: x.get('initial','Other'))\n",
    "\n",
    "initials_map = {k:v for k,v in (zip(['Other','Miss','Mr','Mrs','Master','Mlle','Mme','Ms','Dr',\n",
    "                                               'Major','Lady','Countess',\n",
    "                                               'Jonkheer','Col','Rev',\n",
    "                                               'Capt','Sir','Don'],\n",
    "                                             ['Other','Miss','Mr','Mrs','Mrs','Miss','Miss','Miss',\n",
    "                                              'Mr','Mr','Mrs','Mrs',\n",
    "                                              'Other','Other','Other',\n",
    "                                              'Mr','Mr','Mr']))}\n",
    "train['Initial'] = train['Initial'].map(initials_map)\n",
    "\n",
    "gb = train.groupby(['Initial']).agg({'value':vaex.agg.mean('Age')})\n",
    "means = {k:v for k,v in zip(gb['Initial'].tolist(), gb['value'].tolist())}\n",
    "\n",
    "for initial, value in means.items():    \n",
    "    train['Age'] = train.func.where((train.Age.isna() & train.Initial.str.match(initial)), value, train.Age)\n",
    "\n",
    "train['AgeGroup'] = train.func.where(((train.Sex.str.match('male')) & (train.Age<=15)), 'boy', '')\n",
    "train['AgeGroup'] = train.func.where(((train.Sex.str.match('female')) & (train.Age <= 15)), 'girl', train.AgeGroup)\n",
    "train['AgeGroup'] = train.func.where(((train.Sex.str.match('male')) & (train.Age > 15)), 'adult male', train.AgeGroup)\n",
    "train['AgeGroup'] = train.func.where(((train.Sex.str.match('female')) & (train.Age > 15)), 'adult female', train.AgeGroup)\n",
    "train['FamilyBin'] = train['FamilySize'].digitize(bins= [0,1, 2, 5, 7, 100,1000])\n",
    "\n",
    "\n",
    "string_features = [ 'Embarked', 'Sex', 'FamilyBin', 'AgeGroup'] \n",
    "encoder = LabelEncoder(features=string_features, prefix='le_', allow_unseen=True)\n",
    "train = encoder.fit_transform(train)\n",
    "\n",
    "features = ['PassengerId','Pclass','Age', 'SibSp','Parch','Fare'] +[f\"{encoder.prefix}{column}\" for column in string_features]\n",
    "target = 'Survived'\n",
    "model = LightGBMModel(features=features, \n",
    "                        target=target,                         \n",
    "                        prediction_name='lgm_predictions', \n",
    "                        num_boost_round=500,params={'verbose': -1,\n",
    "                                                   'application':'binary'})\n",
    "model.fit(train)\n",
    "train = model.transform(train)\n",
    "train['prediction'] = train.func.where(train['lgm_predictions'] > 0.5, 1,0)\n",
    "train['target_label'] = train.func.where(train['lgm_predictions'] > 0.5, 'survived','died')\n",
    "pipeline = Pipeline.from_dataframe(train)\n",
    "\n",
    "predictions = pipeline.inference(test, fillna=False)['prediction']\n",
    "print(f\"accuracy: {accuracy_score(test[target].values, predictions.values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-cocktail",
   "metadata": {},
   "source": [
    "## Build Pipeline\n",
    "Oops... one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "swedish-reducing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T18:56:43.032296Z",
     "start_time": "2021-09-17T18:56:42.403763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../models/pipeline.pkl'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pipeline.from_dataframe(train).save('../models/pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fabulous-hampton",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T13:34:30.386407Z",
     "start_time": "2021-09-18T13:34:29.753577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  PassengerId</th><th style=\"text-align: right;\">  Survived</th><th style=\"text-align: right;\">  Pclass</th><th>Name                </th><th>Sex  </th><th style=\"text-align: right;\">  Age</th><th style=\"text-align: right;\">  SibSp</th><th style=\"text-align: right;\">  Parch</th><th style=\"text-align: right;\">  Ticket</th><th style=\"text-align: right;\">  Fare</th><th>Cabin  </th><th>Embarked  </th><th style=\"text-align: right;\">  FamilySize</th><th>Initial  </th><th>AgeGroup  </th><th style=\"text-align: right;\">  FamilyBin</th><th style=\"text-align: right;\">  le_Embarked</th><th style=\"text-align: right;\">  le_Sex</th><th style=\"text-align: right;\">  le_FamilyBin</th><th style=\"text-align: right;\">  le_AgeGroup</th><th style=\"text-align: right;\">  lgm_predictions</th><th style=\"text-align: right;\">  prediction</th><th>target_label  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">           91</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">       3</td><td>Christmann, Mr. Emil</td><td>male </td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">  343276</td><td style=\"text-align: right;\">  8.05</td><td>A B    </td><td>S         </td><td style=\"text-align: right;\">           1</td><td>Mr       </td><td>adult male</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">      0.000656524</td><td style=\"text-align: right;\">           0</td><td>died          </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    PassengerId    Survived    Pclass  Name                  Sex      Age    SibSp    Parch    Ticket    Fare  Cabin    Embarked      FamilySize  Initial    AgeGroup      FamilyBin    le_Embarked    le_Sex    le_FamilyBin    le_AgeGroup    lgm_predictions    prediction  target_label\n",
       "  0             91           0         3  Christmann, Mr. Emil  male      29        0        0    343276    8.05  A B      S                      1  Mr         adult male            2              3         1               0              1        0.000656524             0  died"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# server pipeline\n",
    "from lakeml.vaex.pipeline import Pipeline\n",
    "pipeline = Pipeline.from_file('../models/pipeline.pkl')\n",
    "\n",
    "data = {\"PassengerId\": 91, \n",
    "        \"Survived\": 0, \"Pclass\": 3, \n",
    "        \"Name\": \"Christmann, Mr. Emil\", \n",
    "        \"Sex\": \"male\", \n",
    "        \"Age\": 29.0, \n",
    "        \"SibSp\": 0, \n",
    "        \"Parch\": 0, \n",
    "        \"Ticket\": \"343276\", \"Fare\": 8.05, \n",
    "        \"Cabin\": \"A B\", # this make sure we don't filter\n",
    "        \"Embarked\": \"S\"}\n",
    "pipeline.inference(data, clean=True, set_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-supplier",
   "metadata": {},
   "source": [
    "### For retraining, copy-paste does work here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "advised-point",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T13:32:47.826086Z",
     "start_time": "2021-09-18T13:32:44.846055Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:lakeml.vaex.pipeline:could not sample first: Column or variable '__Age' does not exist. Did you mean: 'Age'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8595505617977528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../models/pipeline.pkl'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vaex\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from vaex.ml.lightgbm import LightGBMModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from vaex.ml import LabelEncoder\n",
    "from icecream import ic \n",
    "from lakeml.vaex import Pipeline\n",
    "\n",
    "import pyarrow as pa\n",
    "import re\n",
    "\n",
    "\n",
    "df = vaex.open('../datasets/titanic.csv')\n",
    "\n",
    "\n",
    "def fit(train):\n",
    "    numeric_cols = ['PassengerId','Survived', 'Pclass', 'Age', 'SibSp','Parch','Ticket','Fare'] \n",
    "    numeric_features = ['PassengerId','Pclass','Age', 'SibSp','Parch','Fare'] \n",
    "    string_features = [ 'Embarked', 'Sex', 'FamilyBin'] \n",
    "    features = numeric_features\n",
    "\n",
    "    train = train[train['Cabin'].str.contains(' ') != True]\n",
    "    train['FamilySize'] = train['Parch'] + train['SibSp'] + 1\n",
    "    train['Name'] = train['Name'].fillna('Mr.')\n",
    "    pattern = re.compile('([A-Za-z]+)\\.')\n",
    "\n",
    "    train['Initial'] = train['Name'].str.extract_regex(r'(?P<initial>[A-Za-z]+)\\.').apply(lambda x: x.get('initial','Other'))\n",
    "\n",
    "    initials_map = {k:v for k,v in (zip(['Other','Miss','Mr','Mrs','Master','Mlle','Mme','Ms','Dr',\n",
    "                                                   'Major','Lady','Countess',\n",
    "                                                   'Jonkheer','Col','Rev',\n",
    "                                                   'Capt','Sir','Don'],\n",
    "                                                 ['Other','Miss','Mr','Mrs','Mrs','Miss','Miss','Miss',\n",
    "                                                  'Mr','Mr','Mrs','Mrs',\n",
    "                                                  'Other','Other','Other',\n",
    "                                                  'Mr','Mr','Mr']))}\n",
    "    train['Initial'] = train['Initial'].map(initials_map)\n",
    "\n",
    "    gb = train.groupby(['Initial']).agg({'value':vaex.agg.mean('Age')})\n",
    "    means = {k:v for k,v in zip(gb['Initial'].tolist(), gb['value'].tolist())}\n",
    "\n",
    "    for initial, value in means.items():    \n",
    "        train['Age'] = train.func.where((train.Age.isna() & train.Initial.str.match(initial)), value, train.Age)\n",
    "\n",
    "    train['AgeGroup'] = train.func.where(((train.Sex.str.match('male')) & (train.Age<=15)), 'boy', '')\n",
    "    train['AgeGroup'] = train.func.where(((train.Sex.str.match('female')) & (train.Age <= 15)), 'girl', train.AgeGroup)\n",
    "    train['AgeGroup'] = train.func.where(((train.Sex.str.match('male')) & (train.Age > 15)), 'adult male', train.AgeGroup)\n",
    "    train['AgeGroup'] = train.func.where(((train.Sex.str.match('female')) & (train.Age > 15)), 'adult female', train.AgeGroup)\n",
    "    train['FamilyBin'] = train['FamilySize'].digitize(bins= [0,1, 2, 5, 7, 100,1000])\n",
    "\n",
    "\n",
    "    string_features = [ 'Embarked', 'Sex', 'FamilyBin', 'AgeGroup'] \n",
    "    encoder = LabelEncoder(features=string_features, prefix='le_', allow_unseen=True)\n",
    "    train = encoder.fit_transform(train)\n",
    "\n",
    "    features = ['PassengerId','Pclass','Age', 'SibSp','Parch','Fare'] +[f\"{encoder.prefix}{column}\" for column in string_features]\n",
    "    target = 'Survived'\n",
    "    model = LightGBMModel(features=features, \n",
    "                            target=target,                         \n",
    "                            prediction_name='lgm_predictions', \n",
    "                            num_boost_round=500,params={'verbose': -1,\n",
    "                                                       'application':'binary'})\n",
    "    model.fit(train)\n",
    "    train = model.transform(train)\n",
    "    train['prediction'] = train.func.where(train['lgm_predictions'] > 0.5, 1,0)\n",
    "    train['target_label'] = train.func.where(train['lgm_predictions'] > 0.5, 'survived','died')\n",
    "    return train\n",
    "\n",
    "pipeline = Pipeline.from_dataframe(df, fit=fit)\n",
    "train, test = df.split_random([0.8, 0.2])\n",
    "pipeline.fit(train)\n",
    "\n",
    "predictions = pipeline.inference(test, fillna=False)['prediction']\n",
    "print(f\"accuracy: {accuracy_score(test['Survived'].values, predictions.values)}\")\n",
    "\n",
    "pipeline.fit(df) # fit on the enitre dataset\n",
    "pipeline.save('../models/pipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-singer",
   "metadata": {},
   "source": [
    "# PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-monster",
   "metadata": {},
   "source": [
    "## POC with Koalas + PySpark\n",
    "POC is similar, plus a workaround here and there...    \n",
    "* This work on big data with a well-calibrated cluster/platform\n",
    "* I have maintained most of the original non-pythonic syntax consistent with the PySpark docs and common examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "developmental-license",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T15:38:20.460648Z",
     "start_time": "2021-09-17T15:38:20.110634Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "import os\n",
    "\n",
    "os.environ['JAVA_HOME'] = \"/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/\"\n",
    "os.environ['PYTHONPATH'] = \"/usr/local/Cellar/apache-spark/2.4.5/libexec//python/lib/py4j-0.10.7-src.zip:/usr/local/Cellar/apache-spark/2.4.5/libexec//python/:\"\n",
    "os.environ['JRE_HOME'] = \"/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/\"\n",
    "os.environ['SPARK_HOME'] = \"/usr/local/Cellar/apache-spark/2.4.5/libexec/\"\n",
    "os.environ['ARROW_PRE_0_15_IPC_FORMAT'] = \"1\"\n",
    "os.environ['PYARROW_IGNORE_TIMEZONE'] = \"1\"\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "# real code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import databricks.koalas as ks\n",
    "from databricks.koalas import DataFrame as KoalasFrame\n",
    "from pyspark.ml.feature import Imputer, StringIndexer, VectorIndexer, VectorAssembler, OneHotEncoderEstimator, PCA, Bucketizer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline as SparkPipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pyspark.sql.functions as F\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "running-pressing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T15:38:42.338171Z",
     "start_time": "2021-09-17T15:38:23.127287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7967032967032966\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT - Only run the next cell when the one before has finished -> this prevent crashes\n",
    "df = ks.read_csv('../datasets/titanic.csv')\n",
    "\n",
    "numeric_cols = ['PassengerId','Survived', 'Pclass', 'Age', 'SibSp','Parch','Ticket','Fare'] \n",
    "numeric_features = ['PassengerId','Pclass','Age', 'SibSp','Parch','Fare'] \n",
    "string_features = [ 'Embarked', 'Sex', 'FamilyBin'] \n",
    "features = numeric_features\n",
    "\n",
    "\n",
    "df = df[df['Cabin'].str.contains(' ') != True]\n",
    "df['FamilySize'] = df['Parch'] + df['SibSp'] + 1\n",
    "\n",
    "sdf = df.to_spark()\n",
    "\n",
    "# df['Initial'] = df['Name'].str.extract(r'([A-Za-z]+)\\.') # not implemented\n",
    "# Workaround\n",
    "def evaluate_initials(sdf):\n",
    "    dizip_initials = {k:v for k,v in (zip(['Miss','Mr','Mrs','Master','Mlle','Mme','Ms','Dr',\n",
    "                                               'Major','Lady','Countess',\n",
    "                                               'Jonkheer','Col','Rev',\n",
    "                                               'Capt','Sir','Don'],\n",
    "                                             ['Miss','Mr','Mrs','Mrs','Miss','Miss','Miss',\n",
    "                                              'Mr','Mr','Mrs','Mrs',\n",
    "                                              'Other','Other','Other',\n",
    "                                              'Mr','Mr','Mr']))}\n",
    "    _sdf = sdf.withColumn('Initial',  F.regexp_extract( sdf['Name'], ('([A-Za-z]+)\\.'),1 ) )\n",
    "    _sdf = _sdf.replace(dizip_initials,1,'Initial')\n",
    "    return _sdf\n",
    "\n",
    "sdf = evaluate_initials(sdf)\n",
    "\n",
    "train, test = sdf.randomSplit([0.8, 0.2])\n",
    "\n",
    "def get_means(df):# pyspark bug -> workaround\n",
    "    df = KoalasFrame(df)\n",
    "    means = df.groupby('Initial').agg({'Age': 'mean'})\n",
    "    index = list(means.index.values) # koalas bug with index\n",
    "    means = means.toPandas()\n",
    "    means.index = index\n",
    "    means = means['Age'].to_dict()\n",
    "    return means\n",
    "\n",
    "means = get_means(train)\n",
    "\n",
    "# Koahlas bugs -> workaround with pyspark\n",
    "# for initial, value in means.items(): \n",
    "#     df.loc[((df['Age'].isnull()) & (df['Initial']==initial)), 'Age'] = value\n",
    "\n",
    "def handle_missing_age(sdf, means):\n",
    "    _sdf = sdf\n",
    "    _sdf = _sdf.withColumn('Age', \n",
    "           F.when((F.isnull(_sdf['Age'])) & (_sdf['Initial'] == 'Mr') , means.get('Mr') )\n",
    "            .otherwise(F.when((F.isnull(_sdf['Age'])) \n",
    "                              & (_sdf['Initial'] == 'Mrs') ,  means.get('Mrs') )\\\n",
    "            .otherwise(F.when((F.isnull(_sdf['Age'])) \n",
    "                              & (_sdf['Initial'] == 'Master') , means.get('Master'))\\\n",
    "            .otherwise(F.when((F.isnull(_sdf['Age'])) \n",
    "                              & (_sdf['Initial'] == 'Miss') , means.get('Miss'))\\\n",
    "            .otherwise(F.when((F.isnull(_sdf['Age'])) \n",
    "                              & (_sdf['Initial'] == 'Other') , means.get('Other'))\\\n",
    "            .otherwise(_sdf['Age']) )))))\n",
    "    return _sdf\n",
    "train = handle_missing_age(train, means)\n",
    "test = handle_missing_age(test, means)\n",
    "\n",
    "def age_group(df):\n",
    "    df = KoalasFrame(df)\n",
    "    df['AgeGroup'] = None\n",
    "    df.loc[((df['Sex'] == 'male') & (df['Age'] <= 15)), 'AgeGroup'] = 'boy'\n",
    "    df.loc[((df['Sex'] == 'female') & (df['Age'] <= 15)), 'AgeGroup'] = 'girl'\n",
    "    df.loc[((df['Sex'] == 'male') & (df['Age'] > 15)), 'AgeGroup'] = 'adult male'\n",
    "    df.loc[((df['Sex'] == 'female') & (df['Age'] > 15)), 'AgeGroup'] = 'adult female'\n",
    "    return df\n",
    "\n",
    "train = age_group(train)\n",
    "test = age_group(test)\n",
    "\n",
    "# move to PySpark for ML oriented transformations\n",
    "train = train.to_spark()\n",
    "test = test.to_spark()\n",
    "train.persist()\n",
    "test.persist()\n",
    "\n",
    "\n",
    "numeric_cols = ['PassengerId','Survived', 'Pclass', 'Age', 'SibSp','Parch','Ticket','Fare'] \n",
    "numeric_features = ['PassengerId','Pclass','Age', 'SibSp','Parch','Fare'] \n",
    "string_features = [ 'Embarked', 'Sex'] \n",
    "\n",
    "\n",
    "stages = []\n",
    "string_indexer =  [StringIndexer(inputCol = column , \\\n",
    "                                 outputCol = column + '_StringIndexer', \n",
    "                                 handleInvalid = \"skip\") for column in string_features]\n",
    "\n",
    "one_hot_encoder = [OneHotEncoderEstimator(\n",
    "    inputCols = [column + '_StringIndexer' for column in string_features ], \\\n",
    "    outputCols =  [column + '_OneHotEncoderEstimator' for column in string_features ])]\n",
    "\n",
    "vect_indexer = [VectorIndexer(\n",
    "    inputCol = column + '_OneHotEncoderEstimator',\n",
    "    outputCol = column + '_VectorIndexer', \n",
    "    maxCategories=10) for column in string_features]\n",
    "\n",
    "familt_size_splits = [1, 2, 5, 7, 100] \n",
    "bucketizer = Bucketizer(splits = familt_size_splits, \n",
    "                        inputCol = 'FamilySize',\n",
    "                        outputCol = 'bucketized_FamilySize')\n",
    "\n",
    "numeric_features += ['bucketized_FamilySize']\n",
    "\n",
    "assemblerInput =  [f  for f in numeric_features]  \n",
    "assemblerInput += [f + \"_VectorIndexer\" for f in string_features]\n",
    "vector_assembler = VectorAssembler(inputCols = assemblerInput, \\\n",
    "                                   outputCol = 'VectorAssembler_features')\n",
    "\n",
    "rf = RandomForestClassifier(labelCol = 'Survived', \n",
    "                            featuresCol = 'VectorAssembler_features', \n",
    "                            numTrees = 100, \n",
    "                            maxDepth = 4, \n",
    "                            maxBins = 1000)\n",
    "\n",
    "stages += string_indexer\n",
    "stages += one_hot_encoder\n",
    "stages += vect_indexer\n",
    "stages += [bucketizer]\n",
    "stages += [vector_assembler]\n",
    "stages += [rf]\n",
    "\n",
    "# Train\n",
    "pipeline = SparkPipeline(stages = stages).fit(train) \n",
    "predictions = KoalasFrame(pipeline.transform(test))\n",
    "results = predictions[['Survived','prediction']].toPandas()\n",
    "\n",
    "\n",
    "# Evalauation\n",
    "# PySpark is broken here so we use Sklearn\n",
    "# evaluator = MulticlassClassificationEvaluator(\n",
    "#     labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "# accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f\"accuracy: {accuracy_score(results['Survived'], results['prediction'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-peripheral",
   "metadata": {},
   "source": [
    "## PySpark pipeline for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rocky-italy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T12:23:15.329599Z",
     "start_time": "2021-09-17T12:23:02.036340Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "import os\n",
    "\n",
    "os.environ['JAVA_HOME'] = \"/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/\"\n",
    "os.environ['PYTHONPATH'] = \"/usr/local/Cellar/apache-spark/2.4.5/libexec//python/lib/py4j-0.10.7-src.zip:/usr/local/Cellar/apache-spark/2.4.5/libexec//python/:\"\n",
    "os.environ['JRE_HOME'] = \"/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home/jre/\"\n",
    "os.environ['SPARK_HOME'] = \"/usr/local/Cellar/apache-spark/2.4.5/libexec/\"\n",
    "os.environ['ARROW_PRE_0_15_IPC_FORMAT'] = \"1\"\n",
    "os.environ['PYARROW_IGNORE_TIMEZONE'] = \"1\"\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "import databricks.koalas as ks\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Transformer as SparkTransformer,PipelineModel\n",
    "from pyspark.ml.param.shared import HasOutputCols, Param, Params\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.sql.functions import lit # for the dummy _transform\n",
    "from databricks.koalas import DataFrame as KoalasFrame\n",
    "from pyspark.ml.feature import Imputer, StringIndexer, VectorIndexer, VectorAssembler, OneHotEncoderEstimator, PCA, Bucketizer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline as SparkPipeline\n",
    "\n",
    "from pyspark.sql import SparkSession, SQLContext, DataFrame\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Titanic-Dataset\").config('spark.driver.memory','15g').getOrCreate()\n",
    "\n",
    "df = spark.read.csv('../datasets/titanic.csv', inferSchema = True, header = True)\n",
    "\n",
    "train, test = df.randomSplit([8.0, 2.0])\n",
    "\n",
    "\n",
    "numeric_cols = ['PassengerId','Survived', 'Pclass', 'Age', 'SibSp','Parch','Ticket','Fare'] \n",
    "numeric_features = ['PassengerId','Pclass','Age', 'SibSp','Parch','Fare'] \n",
    "string_features = [ 'Embarked', 'Sex'] \n",
    "\n",
    "\n",
    "\n",
    "class DropSome(SparkTransformer, HasOutputCols, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DropSome, self).__init__()\n",
    "    \n",
    "\n",
    "    def _transform(self, df) -> DataFrame:        \n",
    "        return df.where(~F.col(\"Cabin\").contains(' '))\n",
    "    \n",
    "\n",
    "# This is Data engineering -> It is so it will work in production\n",
    "class CleaningTransformer(SparkTransformer, HasOutputCols, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CleaningTransformer, self).__init__()\n",
    "    \n",
    "\n",
    "\n",
    "    def _transform(self, df) -> DataFrame:\n",
    "        return self._clean_dataset ( \n",
    "            self._handle_missing_age(\n",
    "            self._evaluate_initials(\n",
    "            self._create_family_size(train)\n",
    "            )) \n",
    "            ,['Ticket','SibSp','Parch'],['Fare'] \n",
    "        )\n",
    "    @staticmethod\n",
    "    def _clean_dataset(sdf: DataFrame, col_to_convert: list, col_to_impute: list) -> DataFrame:\n",
    "        for col in col_to_convert:\n",
    "            sdf = sdf.withColumn(col,sdf[col].cast('double'))\n",
    "        col_to_impute += col_to_convert\n",
    "\n",
    "        imputer = Imputer(inputCols = col_to_impute, outputCols = col_to_impute)\n",
    "        sdf = imputer.fit(sdf).transform(sdf)\n",
    "\n",
    "        return sdf\n",
    "    \n",
    "    @staticmethod\n",
    "    def _handle_missing_age(sdf: DataFrame) -> DataFrame:\n",
    "        # this value should be calcualted in a better world\n",
    "        _sdf = sdf\n",
    "        _sdf = _sdf.withColumn('Age', \n",
    "               F.when((F.isnull(_sdf['Age'])) & (_sdf['Initial'] == 'Mr') , 33 )\n",
    "                .otherwise(F.when((F.isnull(_sdf['Age'])) \n",
    "                                  & (_sdf['Initial'] == 'Mrs') , 36)\\\n",
    "                .otherwise(F.when((F.isnull(_sdf['Age'])) \n",
    "                                  & (_sdf['Initial'] == 'Master') , 5)\\\n",
    "                .otherwise(F.when((F.isnull(_sdf['Age'])) \n",
    "                                  & (_sdf['Initial'] == 'Miss') , 22)\\\n",
    "                .otherwise(F.when((F.isnull(_sdf['Age'])) \n",
    "                                  & (_sdf['Initial'] == 'Other') , 46)\\\n",
    "                .otherwise(_sdf['Age']) )))))\n",
    "        return _sdf\n",
    "    \n",
    "    @staticmethod\n",
    "    def _evaluate_initials(sdf: DataFrame) -> DataFrame:\n",
    "        dizip_initials = {k:v for k,v in (zip(['Mlle','Mme','Ms','Dr',\n",
    "                                               'Major','Lady','Countess',\n",
    "                                               'Jonkheer','Col','Rev',\n",
    "                                               'Capt','Sir','Don'],\n",
    "                                             ['Miss','Miss','Miss',\n",
    "                                              'Mr','Mr','Mrs','Mrs',\n",
    "                                              'Other','Other','Other',\n",
    "                                              'Mr','Mr','Mr']))}\n",
    "        _sdf = sdf.withColumn('Initial',  F.regexp_extract( sdf['Name'], ('([A-Za-z]+)\\.'),1 ) )\n",
    "        _sdf = _sdf.replace(dizip_initials,1,'Initial')\n",
    "        return _sdf\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_family_size(sdf: DataFrame) -> DataFrame :\n",
    "        _sdf = sdf.withColumn('FamilySize', sdf['Parch'] + sdf['SibSp'] + 1 )\n",
    "\n",
    "        return _sdf\n",
    "    \n",
    "\n",
    "class AgeGroupTransformer(SparkTransformer, HasOutputCols, DefaultParamsReadable, DefaultParamsWritable):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AgeGroupTransformer, self).__init__()\n",
    "\n",
    "    def _transform(self, df) -> DataFrame:\n",
    "        df = KoalasFrame(df)\n",
    "        df['AgeGroup'] = None\n",
    "        df.loc[((df['Sex'] == 'male') & (df['Age'] <= 15)), 'AgeGroup'] = 'boy'\n",
    "        df.loc[((df['Sex'] == 'female') & (df['Age'] <= 15)), 'AgeGroup'] = 'girl'\n",
    "        df.loc[((df['Sex'] == 'male') & (df['Age'] > 15)), 'AgeGroup'] = 'adult male'\n",
    "        df.loc[((df['Sex'] == 'female') & (df['Age'] > 15)), 'AgeGroup'] = 'adult female'\n",
    "        return df.to_spark()\n",
    "    \n",
    "# Feature engineering\n",
    "_stages = []\n",
    "\n",
    "drop_some = [DropSome()] # Clearning step -> not to run in inference\n",
    "clean_transformer = [CleaningTransformer()]\n",
    "age_group_transformer = [AgeGroupTransformer()]\n",
    "string_indexer =  [StringIndexer(inputCol = column , \\\n",
    "                                 outputCol = column + '_StringIndexer', \n",
    "                                 handleInvalid = \"skip\") for column in string_features]\n",
    "\n",
    "one_hot_encoder = [OneHotEncoderEstimator(\n",
    "    inputCols = [column + '_StringIndexer' for column in string_features ], \\\n",
    "    outputCols =  [column + '_OneHotEncoderEstimator' for column in string_features ])]\n",
    "\n",
    "vect_indexer = [VectorIndexer(\n",
    "    inputCol = column + '_OneHotEncoderEstimator',\n",
    "    outputCol = column + '_VectorIndexer', \n",
    "    maxCategories=10) for column in string_features]\n",
    "\n",
    "familt_size_splits = [1, 2, 5, 7, 100] \n",
    "bucketizer = Bucketizer(splits = familt_size_splits, \n",
    "                        inputCol = 'FamilySize',\n",
    "                        outputCol = 'bucketized_FamilySize')\n",
    "\n",
    "numeric_features += ['bucketized_FamilySize']\n",
    "\n",
    "assemblerInput =  [f  for f in numeric_features]  \n",
    "assemblerInput += [f + \"_VectorIndexer\" for f in string_features]\n",
    "vector_assembler = VectorAssembler(inputCols = assemblerInput, \\\n",
    "                                   outputCol = 'VectorAssembler_features')\n",
    "\n",
    "rf = RandomForestClassifier(labelCol = 'Survived', \n",
    "                            featuresCol = 'VectorAssembler_features', \n",
    "                            numTrees = 100, \n",
    "                            maxDepth = 4, \n",
    "                            maxBins = 1000)\n",
    "\n",
    "_stages += drop_some\n",
    "_stages += clean_transformer\n",
    "_stages += age_group_transformer\n",
    "_stages += string_indexer\n",
    "_stages += one_hot_encoder\n",
    "_stages += vect_indexer\n",
    "_stages += [bucketizer]\n",
    "_stages += [vector_assembler]\n",
    "_stages += [rf]\n",
    "\n",
    "# Train\n",
    "pipeline = SparkPipeline(stages = _stages).fit(train) \n",
    "\n",
    "# IMPORTANT to not filter in production \n",
    "pipeline.stages = pipeline.stages[1:]\n",
    "\n",
    "!rm -rf ../models/spark_pipeline.sp\n",
    "pipeline.save('../models/spark_pipeline.sp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unknown-croatia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T12:23:37.900092Z",
     "start_time": "2021-09-17T12:23:30.172740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Initial</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>Embarked_StringIndexer</th>\n",
       "      <th>Sex_StringIndexer</th>\n",
       "      <th>Embarked_OneHotEncoderEstimator</th>\n",
       "      <th>Sex_OneHotEncoderEstimator</th>\n",
       "      <th>Embarked_VectorIndexer</th>\n",
       "      <th>Sex_VectorIndexer</th>\n",
       "      <th>bucketized_FamilySize</th>\n",
       "      <th>VectorAssembler_features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240761.11215</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr</td>\n",
       "      <td>adult male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 3.0, 22.0, 1.0, 0.0, 7.25, 1.0, 1.0, 0.0...</td>\n",
       "      <td>[81.39486731357621, 18.605132686423755]</td>\n",
       "      <td>[0.8139486731357624, 0.1860513268642376]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240761.11215</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>adult female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 1.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0, 1.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[2.0, 1.0, 38.0, 1.0, 0.0, 71.2833, 1.0, 0.0, ...</td>\n",
       "      <td>[11.994029202166837, 88.00597079783314]</td>\n",
       "      <td>[0.1199402920216684, 0.8800597079783316]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                                                 Name     Sex   Age  SibSp  Parch        Ticket     Fare Cabin Embarked  FamilySize Initial      AgeGroup  Embarked_StringIndexer  Sex_StringIndexer Embarked_OneHotEncoderEstimator Sex_OneHotEncoderEstimator Embarked_VectorIndexer Sex_VectorIndexer  bucketized_FamilySize                                 VectorAssembler_features                            rawPrediction                               probability  prediction\n",
       "0            1         0       3                              Braund, Mr. Owen Harris    male  22.0    1.0    0.0  240761.11215   7.2500  None        S           2      Mr    adult male                     0.0                0.0                      (1.0, 0.0)                      (1.0)             (1.0, 0.0)             (1.0)                    1.0     [1.0, 3.0, 22.0, 1.0, 0.0, 7.25, 1.0, 1.0, 0.0, 1.0]  [81.39486731357621, 18.605132686423755]  [0.8139486731357624, 0.1860513268642376]         0.0\n",
       "1            2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0    1.0    0.0  240761.11215  71.2833   C85        C           2     Mrs  adult female                     1.0                1.0                      (0.0, 1.0)                      (0.0)             (0.0, 1.0)             (0.0)                    1.0  [2.0, 1.0, 38.0, 1.0, 0.0, 71.2833, 1.0, 0.0, 1.0, 0.0]  [11.994029202166837, 88.00597079783314]  [0.1199402920216684, 0.8800597079783316]         1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# server\n",
    "from pyspark.ml import PipelineModel\n",
    "ks.DataFrame(PipelineModel.load('../models/spark_pipeline.sp').transform(test)).head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}