{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T16:29:06.643824Z",
     "start_time": "2022-02-08T16:29:01.470337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2o6e2tr5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 13124... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">clear-galaxy-1</strong>: <a href=\"https://wandb.ai/xdss/example/runs/2o6e2tr5\" target=\"_blank\">https://wandb.ai/xdss/example/runs/2o6e2tr5</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220208_171724-2o6e2tr5/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2o6e2tr5). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/xdss/example/runs/2yga17jh\" target=\"_blank\">rosy-glitter-2</a></strong> to <a href=\"https://wandb.ai/xdss/example\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/xdss/example/runs/2yga17jh?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x15ad84190>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"example\", entity=\"xdss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T16:29:07.903926Z",
     "start_time": "2022-02-08T16:29:07.871716Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "X, y = make_classification(n_samples=10000, n_informative=10, n_classes=3)\n",
    "\n",
    "lb = LabelBinarizer().fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T16:38:51.925222Z",
     "start_time": "2022-02-08T16:37:31.474942Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonatanalexander/development/xdss/goldilox/.venv/lib/python3.7/site-packages/ipykernel_launcher.py:53: ExperimentalWarning: WeightsAndBiasesCallback is experimental (supported from v2.9.0). The interface can change in the future.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2m7hf9yy) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 13658... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bagging_fraction</td><td>█▁</td></tr><tr><td>bagging_freq</td><td>▁▁</td></tr><tr><td>feature_fraction</td><td>█▁</td></tr><tr><td>lambda_l1</td><td>▁█</td></tr><tr><td>lambda_l2</td><td>█▁</td></tr><tr><td>num_class</td><td>▁▁</td></tr><tr><td>num_leaves</td><td>█▁</td></tr><tr><td>train_accuracy</td><td>█▁</td></tr><tr><td>train_auc</td><td>█▁</td></tr><tr><td>validation_accuracy</td><td>█▁</td></tr><tr><td>validation_auc</td><td>█▁</td></tr><tr><td>verbosity</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bagging_fraction</td><td>0.44835</td></tr><tr><td>bagging_freq</td><td>3</td></tr><tr><td>boosting_type</td><td>gbdt</td></tr><tr><td>feature_fraction</td><td>0.55931</td></tr><tr><td>lambda_l1</td><td>0.00104</td></tr><tr><td>lambda_l2</td><td>6e-05</td></tr><tr><td>metric</td><td>auc_mu</td></tr><tr><td>num_class</td><td>3</td></tr><tr><td>num_leaves</td><td>34</td></tr><tr><td>objective</td><td>multiclass</td></tr><tr><td>train_accuracy</td><td>0.99147</td></tr><tr><td>train_auc</td><td>0.99975</td></tr><tr><td>validation_accuracy</td><td>0.9036</td></tr><tr><td>validation_auc</td><td>0.97951</td></tr><tr><td>verbosity</td><td>-1</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">clear-frost-6</strong>: <a href=\"https://wandb.ai/xdss/example/runs/2m7hf9yy\" target=\"_blank\">https://wandb.ai/xdss/example/runs/2m7hf9yy</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220208_173646-2m7hf9yy/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2m7hf9yy). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/xdss/example/runs/1ye4035j\" target=\"_blank\">denim-dream-7</a></strong> to <a href=\"https://wandb.ai/xdss/example\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-02-08 17:37:36,749]\u001B[0m A new study created in memory with name: experiment\u001B[0m\n",
      "\u001B[32m[I 2022-02-08 17:37:56,126]\u001B[0m Trial 0 finished with value: 0.9798875581216802 and parameters: {'lambda_l1': 3.1835208743218324, 'lambda_l2': 0.0015129601392034257, 'num_leaves': 168, 'feature_fraction': 0.8015472800822189, 'bagging_fraction': 0.6965048482490156, 'bagging_freq': 5}. Best is trial 0 with value: 0.9798875581216802.\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Step must only increase in log calls.  Step 0 < 1; dropping {'lambda_l1': 3.1835208743218324, 'lambda_l2': 0.0015129601392034257, 'num_leaves': 168, 'feature_fraction': 0.8015472800822189, 'bagging_fraction': 0.6965048482490156, 'bagging_freq': 5, 'value': 0.9798875581216802}.\n",
      "\u001B[32m[I 2022-02-08 17:38:08,822]\u001B[0m Trial 1 finished with value: 0.9786793926366119 and parameters: {'lambda_l1': 1.6311852891444218, 'lambda_l2': 0.0036013398978833925, 'num_leaves': 154, 'feature_fraction': 0.7781225246926549, 'bagging_fraction': 0.7993277071494511, 'bagging_freq': 5}. Best is trial 0 with value: 0.9798875581216802.\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Step must only increase in log calls.  Step 1 < 2; dropping {'lambda_l1': 1.6311852891444218, 'lambda_l2': 0.0036013398978833925, 'num_leaves': 154, 'feature_fraction': 0.7781225246926549, 'bagging_fraction': 0.7993277071494511, 'bagging_freq': 5, 'value': 0.9786793926366119}.\n",
      "\u001B[32m[I 2022-02-08 17:38:26,217]\u001B[0m Trial 2 finished with value: 0.9789010371322124 and parameters: {'lambda_l1': 0.0008745378441773493, 'lambda_l2': 3.907101305270964e-05, 'num_leaves': 218, 'feature_fraction': 0.6471857731690189, 'bagging_fraction': 0.47267419641368813, 'bagging_freq': 6}. Best is trial 0 with value: 0.9798875581216802.\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Step must only increase in log calls.  Step 2 < 3; dropping {'lambda_l1': 0.0008745378441773493, 'lambda_l2': 3.907101305270964e-05, 'num_leaves': 218, 'feature_fraction': 0.6471857731690189, 'bagging_fraction': 0.47267419641368813, 'bagging_freq': 6, 'value': 0.9789010371322124}.\n",
      "\u001B[32m[I 2022-02-08 17:38:35,875]\u001B[0m Trial 3 finished with value: 0.9817315416837661 and parameters: {'lambda_l1': 0.0017430238577477218, 'lambda_l2': 0.010000712094551209, 'num_leaves': 76, 'feature_fraction': 0.9398065788388141, 'bagging_fraction': 0.5294344852069037, 'bagging_freq': 3}. Best is trial 3 with value: 0.9817315416837661.\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Step must only increase in log calls.  Step 3 < 4; dropping {'lambda_l1': 0.0017430238577477218, 'lambda_l2': 0.010000712094551209, 'num_leaves': 76, 'feature_fraction': 0.9398065788388141, 'bagging_fraction': 0.5294344852069037, 'bagging_freq': 3, 'value': 0.9817315416837661}.\n",
      "\u001B[32m[I 2022-02-08 17:38:51,129]\u001B[0m Trial 4 finished with value: 0.9809922850502076 and parameters: {'lambda_l1': 0.23042401513733307, 'lambda_l2': 2.63911594140587e-06, 'num_leaves': 128, 'feature_fraction': 0.7170747221766964, 'bagging_fraction': 0.5710858878043054, 'bagging_freq': 6}. Best is trial 3 with value: 0.9817315416837661.\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Step must only increase in log calls.  Step 4 < 5; dropping {'lambda_l1': 0.23042401513733307, 'lambda_l2': 2.63911594140587e-06, 'num_leaves': 128, 'feature_fraction': 0.7170747221766964, 'bagging_fraction': 0.5710858878043054, 'bagging_freq': 6, 'value': 0.9809922850502076}.\n",
      "\u001B[32m[I 2022-02-08 17:38:51,246]\u001B[0m Trial 5 pruned. Trial was pruned at iteration 0.\u001B[0m\n",
      "\u001B[32m[I 2022-02-08 17:38:51,445]\u001B[0m Trial 6 pruned. Trial was pruned at iteration 0.\u001B[0m\n",
      "\u001B[32m[I 2022-02-08 17:38:51,583]\u001B[0m Trial 7 pruned. Trial was pruned at iteration 0.\u001B[0m\n",
      "\u001B[32m[I 2022-02-08 17:38:51,737]\u001B[0m Trial 8 pruned. Trial was pruned at iteration 0.\u001B[0m\n",
      "\u001B[32m[I 2022-02-08 17:38:51,918]\u001B[0m Trial 9 pruned. Trial was pruned at iteration 0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 10\n",
      "Best trial: {'lambda_l1': 0.0017430238577477218, 'lambda_l2': 0.010000712094551209, 'num_leaves': 76, 'feature_fraction': 0.9398065788388141, 'bagging_fraction': 0.5294344852069037, 'bagging_freq': 3}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from wandb.lightgbm import wandb_callback\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "\n",
    "\n",
    "def get_accuracy(y, predictions):\n",
    "    return accuracy_score(y, np.argmax(predictions, axis=1))\n",
    "\n",
    "\n",
    "def get_auc(y, predictions):\n",
    "    return roc_auc_score(lb.transform(y), predictions)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.25)\n",
    "    train = lgb.Dataset(X_train, label=y_train)\n",
    "    validation = lgb.Dataset(X_validation, label=y_validation)\n",
    "\n",
    "    param = {\n",
    "        \"num_class\": 3,\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"auc_mu\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "    }\n",
    "\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc_mu\")\n",
    "    gbm = lgb.train(\n",
    "        param, train, valid_sets=[validation], callbacks=[pruning_callback, wandb_callback]\n",
    "    )\n",
    "    train_predictions = gbm.predict(X_train)\n",
    "    validation_predictions = gbm.predict(X_validation)\n",
    "\n",
    "    validation_auc = get_auc(y_validation, validation_predictions)\n",
    "    param['train_auc'] = get_auc(y_train, train_predictions)\n",
    "    param['validation_auc'] = validation_auc\n",
    "    param['train_accuracy'] = get_accuracy(y_train, train_predictions)\n",
    "    param['validation_accuracy'] = get_accuracy(y_validation, validation_predictions)\n",
    "    param['Step'] = trial.number\n",
    "    wandb.log(param)\n",
    "    return validation_auc\n",
    "\n",
    "\n",
    "wandbc = WeightsAndBiasesCallback(wandb_kwargs={\"project\": \"example\"})\n",
    "\n",
    "study = optuna.create_study(study_name='experiment', direction='maximize')\n",
    "study.optimize(objective, n_trials=10, callbacks=[wandbc])\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}