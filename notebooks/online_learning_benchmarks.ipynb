{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Online learning benchmarks\n",
    "\n",
    "* [LightGBM]()\n",
    "* [XGBoost]()\n",
    "* [Catboost]()\n",
    "* [River]()\n",
    "* [Skleran]()\n",
    "* [Vopal Wabbit]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T15:38:10.664835Z",
     "start_time": "2021-12-14T15:38:06.391124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th>vendor_id  </th><th>pickup_datetime              </th><th>dropoff_datetime             </th><th style=\"text-align: right;\">  passenger_count</th><th>payment_type  </th><th style=\"text-align: right;\">  trip_distance</th><th style=\"text-align: right;\">  pickup_longitude</th><th style=\"text-align: right;\">  pickup_latitude</th><th style=\"text-align: right;\">  rate_code</th><th style=\"text-align: right;\">  store_and_fwd_flag</th><th style=\"text-align: right;\">  dropoff_longitude</th><th style=\"text-align: right;\">  dropoff_latitude</th><th style=\"text-align: right;\">  fare_amount</th><th style=\"text-align: right;\">  surcharge</th><th style=\"text-align: right;\">  mta_tax</th><th style=\"text-align: right;\">  tip_amount</th><th style=\"text-align: right;\">  tolls_amount</th><th style=\"text-align: right;\">  total_amount</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td>VTS        </td><td>2009-01-04 02:52:00.000000000</td><td>2009-01-04 03:02:00.000000000</td><td style=\"text-align: right;\">                1</td><td>CASH          </td><td style=\"text-align: right;\">           2.63</td><td style=\"text-align: right;\">          -73.992 </td><td style=\"text-align: right;\">          40.7216</td><td style=\"text-align: right;\">        nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">           -73.9938</td><td style=\"text-align: right;\">           40.6959</td><td style=\"text-align: right;\">          8.9</td><td style=\"text-align: right;\">        0.5</td><td style=\"text-align: right;\">      nan</td><td style=\"text-align: right;\">        0   </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">          9.4 </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i></td><td>VTS        </td><td>2009-01-04 03:31:00.000000000</td><td>2009-01-04 03:38:00.000000000</td><td style=\"text-align: right;\">                3</td><td>Credit        </td><td style=\"text-align: right;\">           4.55</td><td style=\"text-align: right;\">          -73.9821</td><td style=\"text-align: right;\">          40.7363</td><td style=\"text-align: right;\">        nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">           -73.9558</td><td style=\"text-align: right;\">           40.768 </td><td style=\"text-align: right;\">         12.1</td><td style=\"text-align: right;\">        0.5</td><td style=\"text-align: right;\">      nan</td><td style=\"text-align: right;\">        2   </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">         14.6 </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>2</i></td><td>VTS        </td><td>2009-01-03 15:43:00.000000000</td><td>2009-01-03 15:57:00.000000000</td><td style=\"text-align: right;\">                5</td><td>Credit        </td><td style=\"text-align: right;\">          10.35</td><td style=\"text-align: right;\">          -74.0026</td><td style=\"text-align: right;\">          40.7397</td><td style=\"text-align: right;\">        nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">           -73.87  </td><td style=\"text-align: right;\">           40.7702</td><td style=\"text-align: right;\">         23.7</td><td style=\"text-align: right;\">        0  </td><td style=\"text-align: right;\">      nan</td><td style=\"text-align: right;\">        4.74</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">         28.44</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #  vendor_id    pickup_datetime                dropoff_datetime                 passenger_count  payment_type      trip_distance    pickup_longitude    pickup_latitude    rate_code    store_and_fwd_flag    dropoff_longitude    dropoff_latitude    fare_amount    surcharge    mta_tax    tip_amount    tolls_amount    total_amount\n",
       "  0  VTS          2009-01-04 02:52:00.000000000  2009-01-04 03:02:00.000000000                  1  CASH                       2.63            -73.992             40.7216          nan                   nan             -73.9938             40.6959            8.9          0.5        nan          0                  0            9.4\n",
       "  1  VTS          2009-01-04 03:31:00.000000000  2009-01-04 03:38:00.000000000                  3  Credit                     4.55            -73.9821            40.7363          nan                   nan             -73.9558             40.768            12.1          0.5        nan          2                  0           14.6\n",
       "  2  VTS          2009-01-03 15:43:00.000000000  2009-01-03 15:57:00.000000000                  5  Credit                    10.35            -74.0026            40.7397          nan                   nan             -73.87               40.7702           23.7          0          nan          4.74               0           28.44"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vaex\n",
    "\n",
    "from goldilox import Pipeline\n",
    "\n",
    "df = vaex.open('../../../datasets/taxi_2009_2015_f32.hdf5')\n",
    "df['pickup_datetime']\n",
    "train = df[df['pickup_datetime'].dt.year == 2015]\n",
    "test = df[df['pickup_datetime'].dt.year < 2015]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T15:39:08.565811Z",
     "start_time": "2021-12-14T15:38:10.726091Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonatanalexander/development/xdss/goldilox/.venv/lib/python3.7/site-packages/vaex/arrow/numpy_dispatch.py:72: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  result_data = op['op'](a_data, b_data)\n",
      "/Users/yonatanalexander/development/xdss/goldilox/.venv/lib/python3.7/site-packages/vaex/arrow/numpy_dispatch.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  result_data = op['op'](a_data, b_data)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  pickup_time_x</th><th style=\"text-align: right;\">  pickup_day_x</th><th style=\"text-align: right;\">  pickup_month_x</th><th style=\"text-align: right;\">  pickup_time_y</th><th style=\"text-align: right;\">  pickup_day_y</th><th style=\"text-align: right;\">  pickup_month_y</th><th style=\"text-align: right;\">  pickup_is_weekend</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">      -0.96005 </td><td style=\"text-align: right;\">      0.433884</td><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">       0.279829</td><td style=\"text-align: right;\">     -0.900969</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">                  0</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i></td><td style=\"text-align: right;\">      -0.785317</td><td style=\"text-align: right;\">     -0.974928</td><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">       0.619094</td><td style=\"text-align: right;\">     -0.222521</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">                  1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    pickup_time_x    pickup_day_x    pickup_month_x    pickup_time_y    pickup_day_y    pickup_month_y    pickup_is_weekend\n",
       "  0        -0.96005         0.433884                 0         0.279829       -0.900969                 1                    0\n",
       "  1        -0.785317       -0.974928                 0         0.619094       -0.222521                 1                    1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import vaex.ml\n",
    "\n",
    "target = 'trip_duration_min'\n",
    "train = train.dropna(column_names=['dropoff_latitude', 'dropoff_longitude', 'pickup_latitude'])\n",
    "\n",
    "# Time in transit (minutes) - This is the target variable\n",
    "train['trip_duration_min'] = (train.dropoff_datetime - train.pickup_datetime) /\n",
    "                             np.timedelta64(1, 'm')\n",
    "\n",
    "# Speed (miles per hour) - To be used for cleaning of the training data\n",
    "train['trip_speed_mph'] = train.trip_distance /\n",
    "                          ((train.dropoff_datetime - train.pickup_datetime) /\n",
    "                           np.timedelta64(1, 'h'))\n",
    "\n",
    "# clean data\n",
    "train = train[(train.passenger_count > 0) & (train.passenger_count < 7)]\n",
    "train = train[(train.trip_distance > 0) & (train.trip_distance < 10)]\n",
    "train = train[(train.trip_duration_min > 2) & (train.trip_duration_min < 30)]\n",
    "train = train[(train.trip_speed_mph > 1) & (train.trip_speed_mph < 60)]\n",
    "\n",
    "# Define the NYC boundaries\n",
    "long_min = -74.05\n",
    "long_max = -73.75\n",
    "lat_min = 40.58\n",
    "lat_max = 40.90\n",
    "train = train[(train.pickup_longitude > long_min) & (train.pickup_longitude < long_max) &\n",
    "              (train.pickup_latitude > lat_min) & (train.pickup_latitude < lat_max) &\n",
    "              (train.dropoff_longitude > long_min) & (train.dropoff_longitude < long_max) &\n",
    "              (train.dropoff_latitude > lat_min) & (train.dropoff_latitude < lat_max)]\n",
    "\n",
    "# New features\n",
    "train['pickup_time'] = train.pickup_datetime.dt.hour + train.pickup_datetime.dt.minute / 60.\n",
    "train['pickup_day'] = train.pickup_datetime.dt.dayofweek\n",
    "train['pickup_month'] = train.pickup_datetime.dt.month - 1  # so it starts from 0\n",
    "train['pickup_is_weekend'] = (train.pickup_day >= 5).astype('int')\n",
    "train['pickup_time_x'] = (np.sin(2 * np.pi * train.pickup_time / 24.)).jit_numba()\n",
    "train['pickup_time_y'] = (np.cos(2 * np.pi * train.pickup_time / 24.)).jit_numba()\n",
    "train['pickup_day_x'] = (np.sin(2 * np.pi * train.pickup_day / 7.)).jit_numba()\n",
    "train['pickup_day_y'] = (np.cos(2 * np.pi * train.pickup_day / 7.)).jit_numba()\n",
    "train['pickup_month_x'] = (np.sin(2 * np.pi * train.pickup_month / 12.)).jit_numba()\n",
    "train['pickup_month_y'] = (np.cos(2 * np.pi * train.pickup_month / 12.)).jit_numba()\n",
    "\n",
    "features = train.get_column_names(regex='.*_x') + train.get_column_names(regex='.*_y') + ['pickup_is_weekend']\n",
    "\n",
    "# Preview the features\n",
    "train.head(2)[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T15:39:11.717697Z",
     "start_time": "2021-12-14T15:39:08.569955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transformed.pkl'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed = Pipeline.from_vaex(train)\n",
    "processed.save('transformed.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# River"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T15:39:34.604163Z",
     "start_time": "2021-12-14T15:39:11.721737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c2817a47c34093bf756d2b2b19f677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), Label(value='In progress...')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from vaex.ml.incubator.river import RiverModel\n",
    "import vaex.ml.metrics\n",
    "from river.linear_model import LinearRegression\n",
    "from river import optim\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set up the model\n",
    "model = RiverModel(model=LinearRegression(optimizer=optim.SGD(lr=0.0001), intercept_lr=0.0001),\n",
    "                   batch_size=11_000_000,\n",
    "                   features=features,\n",
    "                   target=target,\n",
    "                   prediction_name='river_predictions')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train, progress='widget')\n",
    "train = model.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T15:39:37.728362Z",
     "start_time": "2021-12-14T15:39:34.605633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transformed1.pkl'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed = Pipeline.from_vaex(train)\n",
    "processed.save('transformed1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vopal Wabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     20
    ]
   },
   "outputs": [],
   "source": [
    "from vowpalwabbit.DFtoVW import DFtoVW\n",
    "from vowpalwabbit.pyvw import vw\n",
    "import tempfile\n",
    "import base64\n",
    "import pandas as pd\n",
    "\n",
    "params = {'P': 1,\n",
    "          \"enable_logging\": True\n",
    "          }\n",
    "model = vw(**params)\n",
    "\n",
    "for _, _, d in train.to_pandas_df(chunk_size=10000):\n",
    "    for ex in DFtoVW.from_colnames(df=d, y=target, x=features).convert_df():\n",
    "        model.learn(ex)\n",
    "\n",
    "model.finish()\n",
    "\n",
    "\n",
    "class VWModell(traitlets.HasTraits):\n",
    "\n",
    "    # This should work with the reduce's arguments\n",
    "    def __init__(self, model=None, features=None, target=None, params=None):\n",
    "        self.params = params or {}\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.model = self._decode_model(model)\n",
    "\n",
    "    # This is how you make a class pickalbe\n",
    "    def __reduce__(self):\n",
    "        return (self.__class__, (self._encode(), self.features, self.target, self.params))\n",
    "\n",
    "    # How vw implemented serialization\n",
    "    def _decode_model(self, encoding):\n",
    "        if encoding is None:\n",
    "            return vw(**self.params)\n",
    "        if isinstance(encoding, str):\n",
    "            model_data = base64.decodebytes(encoding.encode('ascii'))\n",
    "            openfilename = tempfile.mktemp()\n",
    "            with open(openfilename, 'wb') as f:\n",
    "                f.write(model_data)\n",
    "            params = self.params.copy()\n",
    "            params['i'] = openfilename\n",
    "            return vw(**params)\n",
    "        else:\n",
    "            return encoding\n",
    "\n",
    "    # How vw implemented serialization\n",
    "    def _encode(self):\n",
    "        if isinstance(self.model, bytes):\n",
    "            return self.model\n",
    "        filename = tempfile.mktemp()\n",
    "        self.model.save(filename)\n",
    "        with open(filename, 'rb') as f:\n",
    "            model_data = f.read()\n",
    "        encoding = base64.encodebytes(model_data).decode('ascii')\n",
    "        return encoding\n",
    "\n",
    "    def predict(self, data):\n",
    "        if isinstance(data, vaex.dataframe.DataFrame):\n",
    "            data = data.to_pandas_df()\n",
    "        elif isinstance(data, np.ndarray):\n",
    "            data = pd.DataFrame(data, columns=features)\n",
    "        if self.target not in data:\n",
    "            data[self.target] = 1\n",
    "        examples = DFtoVW.from_colnames(df=data, y=target, x=features).convert_df()\n",
    "        return np.array([self.model.predict(ex) for ex in examples])\n",
    "\n",
    "\n",
    "vw_model = VWModell(model=model, features=features, target=target, params=params)\n",
    "\n",
    "\n",
    "@vaex.register_function(on_expression=False)\n",
    "def predict(*columns):\n",
    "    data = np.array(columns).T\n",
    "    return vw_model.predict(data)\n",
    "\n",
    "\n",
    "df.add_function('predict', predict)\n",
    "df['prediction'] = df.func.predict(*features)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import vaex.ml\n",
    "\n",
    "target = 'trip_duration_min'\n",
    "train = train.dropna(column_names=['dropoff_latitude', 'dropoff_longitude', 'pickup_latitude'])\n",
    "\n",
    "# Time in transit (minutes) - This is the target variable\n",
    "train['trip_duration_min'] = (train.dropoff_datetime - train.pickup_datetime) /\n",
    "                             np.timedelta64(1, 'm')\n",
    "\n",
    "# Speed (miles per hour) - To be used for cleaning of the training data\n",
    "train['trip_speed_mph'] = train.trip_distance /\n",
    "                          ((train.dropoff_datetime - train.pickup_datetime) /\n",
    "                           np.timedelta64(1, 'h'))\n",
    "\n",
    "# clean data\n",
    "train = train[(train.passenger_count > 0) & (train.passenger_count < 7)]\n",
    "train = train[(train.trip_distance > 0) & (train.trip_distance < 10)]\n",
    "train = train[(train.trip_duration_min > 2) & (train.trip_duration_min < 30)]\n",
    "train = train[(train.trip_speed_mph > 1) & (train.trip_speed_mph < 60)]\n",
    "\n",
    "# Define the NYC boundaries\n",
    "long_min = -74.05\n",
    "long_max = -73.75\n",
    "lat_min = 40.58\n",
    "lat_max = 40.90\n",
    "train = train[(train.pickup_longitude > long_min) & (train.pickup_longitude < long_max) &\n",
    "              (train.pickup_latitude > lat_min) & (train.pickup_latitude < lat_max) &\n",
    "              (train.dropoff_longitude > long_min) & (train.dropoff_longitude < long_max) &\n",
    "              (train.dropoff_latitude > lat_min) & (train.dropoff_latitude < lat_max)]\n",
    "\n",
    "\n",
    "# New features\n",
    "\n",
    "def arc_distance(theta_1, phi_1, theta_2, phi_2):\n",
    "    temp = (np.sin((theta_2 - theta_1) / 2 * np.pi / 180) ** 2\n",
    "            + np.cos(theta_1 * np.pi / 180) * np.cos(theta_2 * np.pi / 180) * np.sin(\n",
    "                (phi_2 - phi_1) / 2 * np.pi / 180) ** 2)\n",
    "    distance = 2 * np.arctan2(np.sqrt(temp), np.sqrt(1 - temp))\n",
    "    return distance * 3958.8\n",
    "\n",
    "\n",
    "train['arc_distance'] = arc_distance(train.pickup_longitude,\n",
    "                                     train.pickup_latitude,\n",
    "                                     train.dropoff_longitude,\n",
    "                                     train.dropoff_latitude).jit_numba()\n",
    "\n",
    "\n",
    "def direction_angle(theta_1, phi_1, theta_2, phi_2):\n",
    "    dtheta = theta_2 - theta_1\n",
    "    dphi = phi_2 - phi_1\n",
    "    radians = np.arctan2(dtheta, dphi)\n",
    "    return np.rad2deg(radians)\n",
    "\n",
    "\n",
    "train['direction_angle'] = direction_angle(train.pickup_longitude,\n",
    "                                           train.pickup_latitude,\n",
    "                                           train.dropoff_longitude,\n",
    "                                           train.dropoff_latitude).jit_numba()\n",
    "\n",
    "train['direction_angle_x'] = (np.sin(2 * np.pi * train.direction_angle / 360.)).jit_numba()\n",
    "train['direction_angle_y'] = (np.cos(2 * np.pi * train.direction_angle / 360.)).jit_numba()\n",
    "\n",
    "# Select all the features to be used for training the model\n",
    "features = train.get_column_names(regex='.*_x')\n",
    "train.get_column_names(regex='.*_y') + ['pickup_is_weekend']\n",
    "\n",
    "# Preview the features\n",
    "train.head(2)[features]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}