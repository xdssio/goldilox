{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advance pipelines\n",
    "\n",
    "The main idea is to put to the test a complicated, real-world data science problem and solution.    \n",
    "We want to simulate real-world work on the dirty [titanic](https://www.kaggle.com/c/titanic) data.\n",
    "* [Inpiried heavily  by this notebook](https://www.kaggle.com/bombatkarvivek/pyspark-ml-pipeline-with-titanic-dataset-eda).   \n",
    "\n",
    "Pipeline steps:    \n",
    "\n",
    " * Cleaned *Cabin* values that have illegal values are unnecessary, but it is crucial to take cleaning data into account, as it significantly affects the pipeline.    \n",
    " * Calculating *FamilySize = Parch + SibSp + 1* (self)\n",
    " * Get the Initials from the name, and map them to either \"Mr\", \"Miss\", \"Mrs\" and \"Other\".\n",
    " * Calculate the mean *Age* for each Initial and use it to fill missing values for *Age*.\n",
    " * Create *AgeGroup* for each male/female and under/over the age of 15.\n",
    " * Bin *FamilySize* to the [0,1, 2, 5, 7, 100,1000] bins.\n",
    " * Encode *Embarked, Sex, FamilyBin, AgeGroup* with a label/one-hot encoder.\n",
    " * Use [LightGBM](https://lightgbm.readthedocs.io/en/latest/) (or Random Forest for PySpark) for modelling.\n",
    " * Add the survived/died probability in a consumable way.\n",
    "\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  PassengerId</th><th style=\"text-align: right;\">  Survived</th><th style=\"text-align: right;\">  Pclass</th><th>Name                                               </th><th>Sex   </th><th style=\"text-align: right;\">  Age</th><th style=\"text-align: right;\">  SibSp</th><th style=\"text-align: right;\">  Parch</th><th>Ticket   </th><th style=\"text-align: right;\">   Fare</th><th>Cabin  </th><th>Embarked  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">         0</td><td style=\"text-align: right;\">       3</td><td>Braund, Mr. Owen Harris                            </td><td>male  </td><td style=\"text-align: right;\">   22</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td>A/5 21171</td><td style=\"text-align: right;\"> 7.25  </td><td>--     </td><td>S         </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i></td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">       1</td><td>&#x27;Cumings, Mrs. John Bradley (Florence Briggs Tha...</td><td>female</td><td style=\"text-align: right;\">   38</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td>PC 17599 </td><td style=\"text-align: right;\">71.2833</td><td>C85    </td><td>C         </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    PassengerId    Survived    Pclass  Name                                                 Sex       Age    SibSp    Parch  Ticket        Fare  Cabin    Embarked\n",
       "  0              1           0         3  Braund, Mr. Owen Harris                              male       22        1        0  A/5 21171   7.25    --       S\n",
       "  1              2           1         1  'Cumings, Mrs. John Bradley (Florence Briggs Tha...  female     38        1        0  PC 17599   71.2833  C85      C"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vaex\n",
    "df = vaex.open('data/titanic.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vaex solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:goldilox.vaex.pipeline:could not sample first: 'float' object is not iterable\n",
      "ERROR:goldilox.vaex.pipeline:could not sample first: 'float' object is not iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7584269662921348\n"
     ]
    }
   ],
   "source": [
    "import vaex\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from vaex.ml.lightgbm import LightGBMModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from vaex.ml import LabelEncoder\n",
    "from goldilox import Pipeline\n",
    "import vaex.ml\n",
    "import pyarrow as pa\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def fit(df):\n",
    "  numeric_cols = ['PassengerId','Survived', 'Pclass', 'Age', 'SibSp','Parch','Ticket','Fare'] \n",
    "  numeric_features = ['PassengerId','Pclass','Age', 'SibSp','Parch','Fare'] \n",
    "  string_features = [ 'Embarked', 'Sex', 'FamilyBin'] \n",
    "  features = numeric_features\n",
    "\n",
    "  df = df[df['Cabin'].str.contains(' ') != True]\n",
    "  df['FamilySize'] = df['Parch'] + df['SibSp'] + 1\n",
    "  df['Name'] = df['Name'].fillna('Mr.')\n",
    "  pattern = re.compile('([A-Za-z]+)\\.')\n",
    "\n",
    "  df['Initial'] = df['Name'].str.extract_regex(r'(?P<initial>[A-Za-z]+)\\.').apply(lambda x: x.get('initial','Other'))\n",
    "\n",
    "  initials_map = {k:v for k,v in (zip(['Other','Miss','Mr','Mrs','Master','Mlle','Mme','Ms','Dr',\n",
    "                                                'Major','Lady','Countess',\n",
    "                                                'Jonkheer','Col','Rev',\n",
    "                                                'Capt','Sir','Don'],\n",
    "                                              ['Other','Miss','Mr','Mrs','Mrs','Miss','Miss','Miss',\n",
    "                                                'Mr','Mr','Mrs','Mrs',\n",
    "                                                'Other','Other','Other',\n",
    "                                                'Mr','Mr','Mr']))}\n",
    "  df['Initial'] = df['Initial'].map(initials_map)\n",
    "\n",
    "  gb = df.groupby(['Initial']).agg({'value':vaex.agg.mean('Age')})\n",
    "  means = {k:v for k,v in zip(gb['Initial'].tolist(), gb['value'].tolist())}\n",
    "\n",
    "  for initial, value in means.items():    \n",
    "      df['Age'] = df.func.where((df.Age.isna() & df.Initial.str.match(initial)), value, df.Age)\n",
    "\n",
    "  df['AgeGroup'] = df.func.where(((df.Sex.str.match('male')) & (df.Age<=15)), 'boy', '')\n",
    "  df['AgeGroup'] = df.func.where(((df.Sex.str.match('female')) & (df.Age <= 15)), 'girl', df.AgeGroup)\n",
    "  df['AgeGroup'] = df.func.where(((df.Sex.str.match('male')) & (df.Age > 15)), 'adult male', df.AgeGroup)\n",
    "  df['AgeGroup'] = df.func.where(((df.Sex.str.match('female')) & (df.Age > 15)), 'adult female', df.AgeGroup)\n",
    "  df['FamilyBin'] = df['FamilySize'].digitize(bins= [0,1, 2, 5, 7, 100,1000])\n",
    "\n",
    "\n",
    "  string_features = [ 'Embarked', 'Sex', 'FamilyBin', 'AgeGroup'] \n",
    "  encoder = LabelEncoder(features=string_features, prefix='le_', allow_unseen=True)\n",
    "  df = encoder.fit_transform(df)\n",
    "\n",
    "  features = ['PassengerId','Pclass','Age', 'SibSp','Parch','Fare'] +[f\"{encoder.prefix}{column}\" for column in string_features]\n",
    "  target = 'Survived'\n",
    "  model = LightGBMModel(features=features, \n",
    "                          target=target,                         \n",
    "                          prediction_name='lgm_predictions', \n",
    "                          num_boost_round=500,params={'verbose': -1,\n",
    "                                                    'application':'binary'})\n",
    "  model.fit(df)\n",
    "  df = model.transform(df)\n",
    "  df['prediction'] = df.func.where(df['lgm_predictions'] > 0.5, 1,0)\n",
    "  df['target_label'] = df.func.where(df['lgm_predictions'] > 0.5, 'survived','died')\n",
    "  return df\n",
    "\n",
    "train, test = df.ml.train_test_split()\n",
    "pipeline = Pipeline.from_vaex(df, fit=fit)\n",
    "pipeline.fit(train)\n",
    "accuracy = accuracy_score(test['Survived'], pipeline.inference(test)['prediction'])\n",
    "pipeline.fit(df)\n",
    "pipeline.set_variable('accuracy',accuracy)\n",
    "assert pipeline.validate()\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7937219730941704\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import sklearn.pipeline\n",
    "from goldilox import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import dump\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "train, test = train_test_split(df)\n",
    "\n",
    "target = 'Survived'\n",
    "fetures = list(train.columns)\n",
    "fetures.remove(target)\n",
    "\n",
    "\n",
    "dizip_initials = {k:v for k,v in (zip(['Mlle','Mme','Ms','Dr',\n",
    "                                               'Major','Lady','Countess',\n",
    "                                               'Jonkheer','Col','Rev',\n",
    "                                               'Capt','Sir','Don'],\n",
    "                                             ['Miss','Miss','Miss',\n",
    "                                              'Mr','Mr','Mrs','Mrs',\n",
    "                                              'Other','Other','Other',\n",
    "                                              'Mr','Mr','Mr']))}\n",
    "\n",
    "class PandasTransformer(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "     def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "class DropSome(PandasTransformer):\n",
    "    \n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "    \n",
    "    def transform(self, df, **transform_params):\n",
    "        return df[df[self.column].str.contains(' ')!=True]\n",
    "    \n",
    "    \n",
    "class FamilySizeTransformer(PandasTransformer):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        df['FamilySize'] = 1\n",
    "        for column in self.columns:\n",
    "            df['FamilySize'] = df['FamilySize']+df[column]\n",
    "        return df\n",
    "\n",
    "class InitialsTransformer(PandasTransformer):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "        self.initials_map = {k:v for k,v in (zip(['Miss','Mr','Mrs','Mlle','Mme','Ms','Dr',\n",
    "                                               'Major','Lady','Countess',\n",
    "                                               'Jonkheer','Col','Rev',\n",
    "                                               'Capt','Sir','Don'],\n",
    "                                             ['Miss','Mr','Mrs','Miss','Miss','Miss',\n",
    "                                              'Mr','Mr','Mrs','Mrs',\n",
    "                                              'Other','Other','Other',\n",
    "                                              'Mr','Mr','Mr']))}\n",
    "        \n",
    "    def transform(self, df, **transform_params):\n",
    "        df['Initial'] = df[self.column].str.extract(r'([A-Za-z]+)\\.')        \n",
    "        df['Initial'] = df['Initial'].map(self.initials_map)\n",
    "        return df   \n",
    "    \n",
    "\n",
    "class AgeImputer(PandasTransformer):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "        self.means = {}\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.means = X.groupby(['Initial'])['Age'].mean().round().astype(int).to_dict() \n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, df, **transform_params):\n",
    "        for initial, value in self.means.items():\n",
    "            df['Age'] = np.where((df['Age'].isnull()) & (df['Initial'].str.match(initial)),value, df['Age'])\n",
    "        return df   \n",
    "    \n",
    "class AgeGroupTransformer(PandasTransformer):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "    \n",
    "\n",
    "    def transform(self, df, **transform_params):\n",
    "        df['AgeGroup'] = None\n",
    "        df.loc[((df['Sex'] == 'male') & (df['Age'] <= 15)), 'AgeGroup'] = 'boy'\n",
    "        df.loc[((df['Sex'] == 'female') & (df['Age'] <= 15)), 'AgeGroup'] = 'girl'\n",
    "        df.loc[((df['Sex'] == 'male') & (df['Age'] > 15)), 'AgeGroup'] = 'adult male'\n",
    "        df.loc[((df['Sex'] == 'female') & (df['Age'] > 15)), 'AgeGroup'] = 'adult female'\n",
    "        return df\n",
    "  \n",
    "class BinTransformer(PandasTransformer):\n",
    "    def __init__(self, column,bins=None):\n",
    "        self.column = column\n",
    "        self.bins = bins or [0,1, 2, 5, 7, 100,1000]\n",
    "    \n",
    "\n",
    "    def transform(self, df, **transform_params):\n",
    "        df['FamilyBin'] = pd.cut(df[self.column], self.bins).astype(str)\n",
    "        return df\n",
    "\n",
    "\n",
    "class MultiColumnLabelEncoder(PandasTransformer):\n",
    "\n",
    "    def __init__(self, columns = None, prefix='le_', fillna_value=''):\n",
    "        self.columns = columns \n",
    "        self.encoders = {}\n",
    "        self.prefix = prefix\n",
    "        self.fillna_value = fillna_value\n",
    "        \n",
    "    def _add_prefix(self, col):\n",
    "        return f\"{self.prefix}{col}\"\n",
    "    \n",
    "    def preprocess_series(self, s):\n",
    "        return s.fillna(self.fillna_value).values.reshape(-1,1)\n",
    "        \n",
    "    def encode(self, column, X):\n",
    "        return self.encoders[column].transform(self.preprocess_series(X[column])).reshape(-1)\n",
    "        \n",
    "    def fit(self,X, y=None):\n",
    "        for column in self.columns:\n",
    "            le = OrdinalEncoder(handle_unknown='use_encoded_value',\n",
    "                                unknown_value=-1)\n",
    "            self.encoders[column] = le\n",
    "            le.fit(self.preprocess_series(X[column]))\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for column in self.columns:\n",
    "                output[self._add_prefix(column)] = self.encode(column, X)\n",
    "        return output\n",
    "\n",
    "        \n",
    "class FeatureSelector(PandasTransformer):\n",
    "\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "\n",
    "    def transform(self, df, **transform_params):        \n",
    "        return df[self.columns]\n",
    "\n",
    "class LGBMTransformer(PandasTransformer):\n",
    "\n",
    "    def __init__(self, target, features, output_column='prediction', **params):\n",
    "        self.features = features\n",
    "        self.params = params\n",
    "        self.model = None\n",
    "        self.target = target\n",
    "        self.output_column = output_column\n",
    "        \n",
    "    def fit(self,X, y):\n",
    "        self.model = LGBMClassifier(**self.params).fit(X[self.features], X[self.target])\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model is not trained\")\n",
    "        return self.model.predict(X[self.features])\n",
    "\n",
    "    def transform(self, df, **transform_params):        \n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model is not trained\")\n",
    "        missing_features = [feature for feature in self.features if feature not in df]\n",
    "        if len(missing_features)>0:\n",
    "            raise RuntimeError(f\"Features missing: {missing_features}\")\n",
    "        \n",
    "        df['prediction'] = self.model.predict(df[self.features])\n",
    "        probabilities = self.model.predict_proba(df[self.features])        \n",
    "        df['probabilities'] = [{'died':p[0],'survived':p[1]} for p in probabilities]\n",
    "        df['label'] = df['prediction'].map({1:'survived',0:'died'})\n",
    "        return df\n",
    "    \n",
    "\n",
    "class CleaningTransformer(PandasTransformer):   \n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def transform(self, df, **transform_params):        \n",
    "        return df[df[self.column].str.contains(' ')!=True]\n",
    "    \n",
    "    \n",
    "sk_pipeline = sklearn.pipeline.Pipeline([\n",
    "    ('cleaning',CleaningTransformer('Cabin')),\n",
    "    ('FamilySizeTransformer', FamilySizeTransformer(['Parch','SibSp'])),\n",
    "    ('InitialsTransformer', InitialsTransformer('Name')),\n",
    "    ('AgeImputer', AgeImputer('Age')),\n",
    "    ('AgeGroupTransformer', AgeGroupTransformer('Age')),\n",
    "    ('BinTransformer', BinTransformer('FamilySize')),\n",
    "    ('MultiColumnLabelEncoder', MultiColumnLabelEncoder(columns=['Embarked', 'Sex', 'FamilyBin'])),\n",
    "    ('model', LGBMTransformer(target='Survived', features=['PassengerId','Pclass', 'Age', 'SibSp', \n",
    "                                        'Parch', 'Fare', 'le_Embarked','le_Sex', 'le_FamilyBin'],verbose=-1)),\n",
    "    ])\n",
    "\n",
    "\n",
    "# train\n",
    "target = 'Survived'\n",
    "fetures = list(train.columns)\n",
    "fetures.remove(target)\n",
    "\n",
    "X = train[fetures]\n",
    "y = train['Survived']\n",
    "\n",
    "\n",
    "trained_pipeline = sk_pipeline.fit(train)\n",
    "trained_pipeline.steps = trained_pipeline.steps[1:] # IMPORTANT - remove the filtering for inference\n",
    "accuracy = accuracy_score(test[target], trained_pipeline.predict(test))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "pipeline = Pipeline.from_sklearn(sk_pipeline).fit(df)\n",
    "pipeline.variables['accuracy'] = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.raw.pop('Survived', None)\n",
    "print(f\"Saved to: {pipeline.save('pipeline.pkl')}\")\n",
    "print(f\"Check out the docs: http://127.0.0.1:5000/docs\\n\")\n",
    "\n",
    "!gl serve pipeline.pkl"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c02e8cefd04ff52e799f4aa259d2ee492875245d06169a1d386f6f6b41a66828"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
