{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Vowpal wabbit](https://vowpalwabbit.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vaex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numbers import Number\n",
    "\n",
    "import numpy as np\n",
    "import vaex\n",
    "from vowpalwabbit.DFtoVW import DFtoVW\n",
    "from vowpalwabbit.pyvw import vw\n",
    "from vaex.ml.datasets import load_titanic\n",
    "\n",
    "from goldilox import Pipeline\n",
    "\n",
    "df, test = load_titanic().ml.train_test_split(test_size=0.2, verbose=False)\n",
    "target = 'survived'\n",
    "features = df.get_column_names(regex=f\"[^{target}]\")\n",
    "df['survived'] = df['survived'].astype('int')+1 # in VW classification is with int starting from 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.297994 0.000000         1047         1047.0        1        1        8\n",
      " \n",
      " finished run\n",
      " number of examples = 1047\n",
      " weighted example sum = 1047.000000\n",
      " weighted label sum = 0.000000\n",
      " average loss = 0.297994\n",
      " total feature number = 11934\n",
      "\n",
      "example:\n",
      "1 | pclass:3 name=Zimmerman, Mr. Leo age:29.0 parch:0 ticket=315082 fare:7.875    \n",
      "prediction: 1\n"
     ]
    }
   ],
   "source": [
    "params = {'P':1, \n",
    "          \"enable_logging\": True, \n",
    "          'link': 'logistic',\n",
    "          'oaa': 2}# two classes\n",
    "model = vw(**params)\n",
    "\n",
    "for _,_,d in df.to_pandas_df(chunk_size=10):\n",
    "    for ex in DFtoVW.from_colnames(df=d, y=target, x=features).convert_df():\n",
    "        model.learn(ex)\n",
    "\n",
    "model.finish()     \n",
    "print(' '.join(model.get_log()[-8:]))\n",
    "print(f\"example:\\n{ex}\\nprediction: {model.predict(ex)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, VW is not pickable, it has it's own implementation for serialization.    \n",
    "It is a small bummer, but we can go around it by implementing a class with *\\_\\_reduce\\_\\_()* which implement the VW serialization.     \n",
    "\n",
    "This is how we can take any model to production as long as there is a way to save it to file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  pclass</th><th style=\"text-align: right;\">  survived</th><th>name                                     </th><th>sex   </th><th style=\"text-align: right;\">  age</th><th style=\"text-align: right;\">  sibsp</th><th style=\"text-align: right;\">  parch</th><th style=\"text-align: right;\">  ticket</th><th style=\"text-align: right;\">  fare</th><th>cabin  </th><th>embarked  </th><th>boat  </th><th style=\"text-align: right;\">  body</th><th>home_dest  </th><th style=\"text-align: right;\">  prediction</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Silvey, Mr. William Baird                </td><td>male  </td><td style=\"text-align: right;\">   50</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   13507</td><td style=\"text-align: right;\">  55.9</td><td>E44    </td><td>S         </td><td>--    </td><td style=\"text-align: right;\">   nan</td><td>Duluth, MN </td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i></td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         2</td><td>Silvey, Mrs. William Baird (Alice Munger)</td><td>female</td><td style=\"text-align: right;\">   39</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   13507</td><td style=\"text-align: right;\">  55.9</td><td>E44    </td><td>S         </td><td>11    </td><td style=\"text-align: right;\">   nan</td><td>Duluth, MN </td><td style=\"text-align: right;\">           1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    pclass    survived  name                                       sex       age    sibsp    parch    ticket    fare  cabin    embarked    boat      body  home_dest      prediction\n",
       "  0         1           1  Silvey, Mr. William Baird                  male       50        1        0     13507    55.9  E44      S           --         nan  Duluth, MN              1\n",
       "  1         1           2  Silvey, Mrs. William Baird (Alice Munger)  female     39        1        0     13507    55.9  E44      S           11         nan  Duluth, MN              1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import traitlets\n",
    "import tempfile\n",
    "import base64\n",
    "import pandas as pd\n",
    "\n",
    "class VWModell(traitlets.HasTraits):\n",
    "\n",
    "        # This should work with the reduce's arguments\n",
    "        def __init__(self, model=None, features=None, target=None, params=None):\n",
    "            self.params = params or {}\n",
    "            self.features = features\n",
    "            self.target = target            \n",
    "            self.model = self._decode_model(model)\n",
    "\n",
    "        # This is how you make a class pickalbe\n",
    "        def __reduce__(self):\n",
    "            return (self.__class__, (self._encode(), self.features, self.target, self.params))\n",
    "\n",
    "        # How vw implemented serialization\n",
    "        def _decode_model(self, encoding):       \n",
    "            if encoding is None:\n",
    "                return vw(**self.params)                \n",
    "            if isinstance(encoding, str):                \n",
    "                model_data = base64.decodebytes(encoding.encode('ascii'))\n",
    "                openfilename = tempfile.mktemp()\n",
    "                with open(openfilename, 'wb') as f:\n",
    "                    f.write(model_data)\n",
    "                params = self.params.copy()\n",
    "                params['i']= openfilename\n",
    "                return vw(**params)\n",
    "            else:\n",
    "                return encoding\n",
    "\n",
    "        # How vw implemented serialization\n",
    "        def _encode(self):\n",
    "            if isinstance(self.model, bytes):\n",
    "                return self.model\n",
    "            filename = tempfile.mktemp()\n",
    "            self.model.save(filename)\n",
    "            with open(filename, 'rb') as f:\n",
    "                model_data = f.read()\n",
    "            encoding =  base64.encodebytes(model_data).decode('ascii')\n",
    "            return encoding   \n",
    "        \n",
    "        def predict(self, data):   \n",
    "            if isinstance(data, vaex.dataframe.DataFrame):\n",
    "                data = data.to_pandas_df()\n",
    "            elif isinstance(data, np.ndarray):\n",
    "                data = pd.DataFrame(data, columns=features)  \n",
    "            if self.target not in data:                \n",
    "                data[self.target] = 1\n",
    "            examples = DFtoVW.from_colnames(df=data, y=target, x=features).convert_df()            \n",
    "            return np.array([self.model.predict(ex) for ex in examples])\n",
    "\n",
    "vw_model = VWModell(model=model, features=features, target=target, params=params)\n",
    "\n",
    "@vaex.register_function(on_expression=False)\n",
    "def predict(*columns):\n",
    "    data = np.array(columns).T                \n",
    "    return vw_model.predict(data)\n",
    "\n",
    "df.add_function('predict',predict)\n",
    "df['prediction'] = df.func.predict(*features)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate:   \n",
    "We use the pipeline here to apply the model on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6297709923664122\n"
     ]
    }
   ],
   "source": [
    "from goldilox import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pipeline = Pipeline.from_vaex(df)\n",
    "accuracy = accuracy_score(pipeline.inference(test)[\"prediction\"].values, test[target].values)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ../tests/models/server.pkl\n",
      "Check out the docs: http://127.0.0.1:5000\n",
      "\n",
      "[2021-11-27 20:11:02 +0100] [80217] [INFO] Starting gunicorn 20.1.0\n",
      "[2021-11-27 20:11:02 +0100] [80217] [INFO] Listening at: http://127.0.0.1:5000 (80217)\n",
      "[2021-11-27 20:11:02 +0100] [80217] [INFO] Using worker: uvicorn.workers.UvicornH11Worker\n",
      "[2021-11-27 20:11:02 +0100] [80242] [INFO] Booting worker with pid: 80242\n",
      "[2021-11-27 20:11:02 +0100] [80242] [INFO] Started server process [80242]\n",
      "[2021-11-27 20:11:02 +0100] [80242] [INFO] Waiting for application startup.\n",
      "[2021-11-27 20:11:02 +0100] [80242] [INFO] Application startup complete.\n",
      "^C\n",
      "[2021-11-27 20:11:43 +0100] [80217] [INFO] Handling signal: int\n"
     ]
    }
   ],
   "source": [
    "print(f\"Saved to: {pipeline.save('../tests/models/server.pkl')}\")\n",
    "print(f\"Check out the docs: http://127.0.0.1:5000\\n\")\n",
    "!gl serve ../tests/models/server.pkl"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c02e8cefd04ff52e799f4aa259d2ee492875245d06169a1d386f6f6b41a66828"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
