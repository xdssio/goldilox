{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [River](https://github.com/online-ml/river)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vaex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T12:41:09.530275Z",
     "start_time": "2021-11-18T12:41:02.327535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  pclass</th><th>survived  </th><th>name                         </th><th>sex   </th><th style=\"text-align: right;\">  age</th><th style=\"text-align: right;\">  sibsp</th><th style=\"text-align: right;\">  parch</th><th style=\"text-align: right;\">  ticket</th><th style=\"text-align: right;\">   fare</th><th>cabin  </th><th>embarked  </th><th style=\"text-align: right;\">  boat</th><th style=\"text-align: right;\">  body</th><th>home_dest   </th><th>predictions  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">       1</td><td>True      </td><td>Allen, Miss. Elisabeth Walton</td><td>female</td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   24160</td><td style=\"text-align: right;\">211.338</td><td>B5     </td><td>S         </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">   nan</td><td>St Louis, MO</td><td>False        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    pclass  survived    name                           sex       age    sibsp    parch    ticket     fare  cabin    embarked      boat    body  home_dest     predictions\n",
       "  0         1  True        Allen, Miss. Elisabeth Walton  female     29        0        0     24160  211.338  B5       S                2     nan  St Louis, MO  False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numbers import Number\n",
    "\n",
    "import numpy as np\n",
    "import vaex\n",
    "from river import compose\n",
    "from river.linear_model import LogisticRegression\n",
    "from river.metrics import Accuracy\n",
    "from river.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from vaex.ml.datasets import load_titanic\n",
    "\n",
    "from goldilox import Pipeline\n",
    "\n",
    "\n",
    "df = load_titanic()\n",
    "features = df.get_column_names()\n",
    "features.remove('survived')\n",
    "\n",
    "# River pipeline\n",
    "num = compose.SelectType(Number) | StandardScaler()\n",
    "cat = compose.SelectType(str) | OneHotEncoder()\n",
    "model = (num + cat) | LogisticRegression()\n",
    "\n",
    "metric = Accuracy()\n",
    "for x in df.to_records():\n",
    "    y = bool(x.pop('survived'))\n",
    "    y_pred = model.predict_one(x)\n",
    "    metric = metric.update(y, y_pred)\n",
    "    model = model.learn_one(x, y)\n",
    "\n",
    "\n",
    "@vaex.register_function(on_expression=False)\n",
    "def predict(*columns):\n",
    "    batch = np.array(columns).T\n",
    "    return np.array(\n",
    "        [model.predict_one({feature: value for feature, value in zip(values, features)}) for values in batch])\n",
    "\n",
    "df.add_function('predict', predict)\n",
    "df['predictions'] = df.func.predict(*tuple([df[col] for col in features]))\n",
    "pipeline = Pipeline.from_vaex(df)\n",
    "assert pipeline.validate()\n",
    "pipeline.inference(pipeline.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With fit\n",
    "For retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T12:46:39.195084Z",
     "start_time": "2021-11-18T12:46:32.279867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  pclass</th><th>survived  </th><th>name                         </th><th>sex   </th><th style=\"text-align: right;\">  age</th><th style=\"text-align: right;\">  sibsp</th><th style=\"text-align: right;\">  parch</th><th style=\"text-align: right;\">  ticket</th><th style=\"text-align: right;\">   fare</th><th>cabin  </th><th>embarked  </th><th style=\"text-align: right;\">  boat</th><th style=\"text-align: right;\">  body</th><th>home_dest   </th><th>predictions  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">       1</td><td>True      </td><td>Allen, Miss. Elisabeth Walton</td><td>female</td><td style=\"text-align: right;\">   29</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   24160</td><td style=\"text-align: right;\">211.338</td><td>B5     </td><td>S         </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">   nan</td><td>St Louis, MO</td><td>False        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    pclass  survived    name                           sex       age    sibsp    parch    ticket     fare  cabin    embarked      boat    body  home_dest     predictions\n",
       "  0         1  True        Allen, Miss. Elisabeth Walton  female     29        0        0     24160  211.338  B5       S                2     nan  St Louis, MO  False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaex.ml.datasets import load_titanic \n",
    "from goldilox import Pipeline\n",
    "\n",
    "def fit(df):\n",
    "    import numpy as np\n",
    "    import vaex\n",
    "    from numbers import Number\n",
    "    from river import compose\n",
    "    from river.linear_model import LogisticRegression\n",
    "    from river.metrics import Accuracy\n",
    "    from river.preprocessing import StandardScaler, OneHotEncoder\n",
    "    \n",
    "    target = 'survived'\n",
    "    features = df.get_column_names()\n",
    "    features.remove(target)\n",
    "\n",
    "    # River pipeline\n",
    "    num = compose.SelectType(Number) | StandardScaler()\n",
    "    cat = compose.SelectType(str) | OneHotEncoder()\n",
    "    model = (num + cat) | LogisticRegression()\n",
    "\n",
    "    metric = Accuracy()\n",
    "    for x in df.to_records():\n",
    "        y = bool(x.pop(target))\n",
    "        y_pred = model.predict_one(x)\n",
    "        metric = metric.update(y, y_pred)\n",
    "        model = model.learn_one(x, y)\n",
    "\n",
    "    @vaex.register_function(on_expression=False)\n",
    "    def predict(*columns):\n",
    "        batch = np.array(columns).T\n",
    "        return np.array(\n",
    "            [model.predict_one({feature: value for feature, value in zip(values, features)}) for values in batch])\n",
    "\n",
    "    df.add_function('predict', predict)\n",
    "    df['predictions'] = df.func.predict(*tuple([df[col] for col in features]))\n",
    "    return df\n",
    "\n",
    "df = load_titanic()\n",
    "pipeline = Pipeline.from_vaex(df, fit=fit).fit(df)\n",
    "pipeline.validate()\n",
    "pipeline.inference(pipeline.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skleran "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numbers import Number\n",
    "\n",
    "import numpy as np\n",
    "import vaex\n",
    "from river import compose\n",
    "from river.linear_model import LogisticRegression\n",
    "from river.metrics import Accuracy\n",
    "from river.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from vaex.ml.datasets import load_titanic\n",
    "from goldilox import Pipeline\n",
    "\n",
    "\n",
    "class RiverLogisticRegression(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, target, output_column='predictions'):\n",
    "        num = compose.SelectType(Number) | StandardScaler()\n",
    "        cat = compose.SelectType(str) | OneHotEncoder()\n",
    "        model = (num + cat) | LogisticRegression()\n",
    "\n",
    "        self.model = model\n",
    "        self.target = target\n",
    "        self.metric = Accuracy()\n",
    "        self.output_column = output_column\n",
    "\n",
    "    def iterate(self, X, y):\n",
    "        if y is not None:\n",
    "            X = X.drop(self.target, errors='ignore')\n",
    "            return zip(X, y)\n",
    "        for x in df.to_dict(orient='records'):\n",
    "            y = x.pop(self.target, None)\n",
    "            yield x, y\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        for x, y in self.iterate(X, y):\n",
    "            y_pred = self.model.predict_one(x)\n",
    "            self.metric.update(y, y_pred)\n",
    "            self.model.learn_one(x, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.model.predict_one(x) for x in X.to_dict(orient='records')])\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.drop(self.target, errors='ignore')\n",
    "        X[self.output_column] = self.predict(X)\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)\n",
    "\n",
    "df = load_titanic().to_pandas_df() \n",
    "pipeline = Pipeline.from_sklearn(RiverLogisticRegression('survived')).fit(df)\n",
    "\n",
    "assert pipeline.validate()\n",
    "pipeline.inference(pipeline.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-18T12:47:06.252547Z",
     "start_time": "2021-11-18T12:46:43.150659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ../tests/models/server.pkl\n",
      "Check out the docs: http://127.0.0.1:5000\n",
      "\n",
      "[2021-11-18 13:46:47 +0100] [71380] [INFO] Starting gunicorn 20.1.0\n",
      "[2021-11-18 13:46:47 +0100] [71380] [INFO] Listening at: http://127.0.0.1:5000 (71380)\n",
      "[2021-11-18 13:46:47 +0100] [71380] [INFO] Using worker: uvicorn.workers.UvicornH11Worker\n",
      "[2021-11-18 13:46:47 +0100] [71384] [INFO] Booting worker with pid: 71384\n",
      "[2021-11-18 13:46:47 +0100] [71384] [INFO] Started server process [71384]\n",
      "[2021-11-18 13:46:47 +0100] [71384] [INFO] Waiting for application startup.\n",
      "[2021-11-18 13:46:47 +0100] [71384] [INFO] Application startup complete.\n",
      "^C\n",
      "[2021-11-18 13:47:05 +0100] [71380] [INFO] Handling signal: int\n",
      "[2021-11-18 13:47:05 +0100] [71380] [WARNING] Worker with pid 71384 was terminated due to signal 3\n",
      "[2021-11-18 13:47:05 +0100] [71380] [INFO] Shutting down: Master\n"
     ]
    }
   ],
   "source": [
    "print(f\"Saved to: {pipeline.save('../tests/models/server.pkl')}\")\n",
    "print(f\"Check out the docs: http://127.0.0.1:5000\\n\")\n",
    "!gl serve ../tests/models/server.pkl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
