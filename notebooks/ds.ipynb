{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "commercial-cleanup",
   "metadata": {},
   "source": [
    "# Every branch a server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "measured-fundamental",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T10:57:21.305720Z",
     "start_time": "2021-09-14T10:57:18.438235Z"
    },
    "code_folding": [],
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from lakeml.vaex import Pipeline\n",
    "models_path = '../models'\n",
    "import lakefs_client\n",
    "from lakefs_client.models import RepositoryCreation\n",
    "from lakefs_client.client import LakeFSClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import vaex\n",
    "import sys\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from lakeml.vaex.core.variables import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from lakeml.vaex import Pipeline\n",
    "models_path = '../models'\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.username = os.getenv('LAKEFS_USER')\n",
    "configuration.password = os.getenv('LAKEFS_PASSWORD')\n",
    "configuration.host = os.getenv('LAKEFS_HOST')\n",
    "client= LakeFSClient(configuration)\n",
    "\n",
    "def lakefs_open(path):\n",
    "    splits = path.split('/')\n",
    "    repo = splits[2]\n",
    "    branch = splits[3]\n",
    "    filename = splits[4]\n",
    "    path = f\"../data/{repo}/{branch}/{filename}\"\n",
    "    ret = vaex.open(path)\n",
    "    ret.variables['lakefs'] = {'repo':repo,'branch':branch}\n",
    "    return ret\n",
    "\n",
    "def lakefs_commit(pipeline, path, hooks=None):\n",
    "    splits = path.split('/')\n",
    "    repo = splits[2]\n",
    "    branch = splits[3]\n",
    "    filename = splits[4]\n",
    "    path = f\"../data/{repo}/{branch}/{filename}\"\n",
    "    if hooks is not None:\n",
    "        for hook in hooks:\n",
    "            if hook(pipeline) is False:\n",
    "                raise RuntimeError(\"invalid pipeline\")\n",
    "    pipeline.save(path)\n",
    "\n",
    "def lakefs_load(path):\n",
    "    splits = path.split('/')\n",
    "    repo = splits[2]\n",
    "    branch = splits[3]\n",
    "    filename = splits[4]\n",
    "    path = f\"../data/{repo}/{branch}/{filename}\"\n",
    "    return Pipeline.from_file(path)\n",
    "\n",
    "def validate_evaluation(pipeline):\n",
    "    print('validateing \"accuracy\" ')\n",
    "    safe = True\n",
    "    for key in ['accuracy']:\n",
    "        if key not in pipeline.variables.get('evaluation',{}):\n",
    "            print(f\"{key} is missing\")\n",
    "            safe = False\n",
    "    return safe\n",
    "\n",
    "def validate_output(pipeline):\n",
    "    print('validateing \"prediction\" column exists')\n",
    "    if not 'prediction' in pipeline.example.column_names:\n",
    "        print(\"prediction column is missing\")\n",
    "    return 'prediction' in pipeline.example.column_names        \n",
    "\n",
    "\n",
    "@vaex.register_dataframe_accessor('lakefs', override=True)\n",
    "class LakeFSAccessor(object):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.client = LakeFSClient(configuration)\n",
    "        \n",
    "    def _list_branches(self, repo=None):\n",
    "        repo = repo or self.df.lakefs.repo\n",
    "        return self.client.branches.list_branches(repo)\n",
    "\n",
    "    @property\n",
    "    def branch(self):\n",
    "        return self.df.variables.get('lakefs',{}).get('branch')\n",
    "    \n",
    "    @property\n",
    "    def branches(self):\n",
    "        return self._list_branches()['results']\n",
    "    \n",
    "    @property\n",
    "    def repo(self):\n",
    "        return self.df.variables.get('lakefs',{}).get('repo')\n",
    "# client.repositories.create_repository(RepositoryCreation(name='server', storage_namespace='local:///Users/yonatanalexander/Dropbox/Development_box/xdss-projects/lakeml/data/server', default_branch='main'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-coupon",
   "metadata": {},
   "source": [
    "### First scientist build model - Classification/Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "american-hierarchy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T15:21:42.020435Z",
     "start_time": "2021-09-13T15:21:42.017077Z"
    }
   },
   "outputs": [],
   "source": [
    "#client.branches.create_branch(repository='server',  \\\n",
    "#  branch_creation=models.BranchCreation(name='lightgbm', source='main'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pediatric-tribune",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T14:16:42.846556Z",
     "start_time": "2021-09-14T14:16:32.029556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: lakefs://server/lightgbm/pipeline.pkl\n",
      "Data: {\"sepal_length\": 5.9, \"sepal_width\": 3.0, \"petal_length\": 4.2, \"petal_width\": 1.5, \"class_\": 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  sepal_length</th><th style=\"text-align: right;\">  sepal_width</th><th style=\"text-align: right;\">  petal_length</th><th style=\"text-align: right;\">  petal_width</th><th style=\"text-align: right;\">  class_</th><th>lgm_predictions                                    </th><th style=\"text-align: right;\">  prediction</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">           5.9</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">           4.2</td><td style=\"text-align: right;\">          1.5</td><td style=\"text-align: right;\">       1</td><td>&#x27;array([6.04909665e-09, 9.99999993e-01, 1.266636...</td><td style=\"text-align: right;\">           1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    sepal_length    sepal_width    petal_length    petal_width    class_  lgm_predictions                                        prediction\n",
       "  0             5.9              3             4.2            1.5         1  'array([6.04909665e-09, 9.99999993e-01, 1.266636...             1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vaex\n",
    "import numpy as np\n",
    "from vaex.ml.lightgbm import LightGBMModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "train, test = vaex.ml.datasets.load_iris_1e5().ml.train_test_split(test_size=0.2, verbose=False)\n",
    "features = ['petal_length', 'petal_width', 'sepal_length', 'sepal_width']\n",
    "target = 'class_'\n",
    "\n",
    "\n",
    "booster = LightGBMModel(features=features, \n",
    "                        target=target,                         \n",
    "                        prediction_name='lgm_predictions', \n",
    "                        num_boost_round=500, params={'verbose': -1,\n",
    "                                                     'objective':'multiclass',\n",
    "                                                    'num_class':3})\n",
    "booster.fit(train)\n",
    "train = booster.transform(train)\n",
    "\n",
    "@vaex.register_function()\n",
    "def argmax(ar, axis=1):\n",
    "    return np.argmax(ar,axis=axis)\n",
    "\n",
    "train.add_function('argmax',argmax)\n",
    "train['prediction'] = train['lgm_predictions'].argmax()\n",
    "\n",
    "pipeline = Pipeline.from_dataframe(train)\n",
    "pipeline.set_variable('accuracy', accuracy_score(pipeline.inference(test[features])['prediction'].values, test[target].values))\n",
    "path = 'lakefs://server/lightgbm/pipeline.pkl'\n",
    "data = test.gl.to_records(0)\n",
    "lakefs_commit(pipeline, path) # commit\n",
    "print(f\"Path: {path}\\nData: {json.dumps(data)}\")\n",
    "pipeline.inference(test).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-physiology",
   "metadata": {},
   "source": [
    "## Second data scietist solves another problem - Nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.branches.create_branch(repository='server',  \\\n",
    "#  branch_creation=models.BranchCreation(name='knn', source='main'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lined-brighton",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T15:23:40.384093Z",
     "start_time": "2021-09-13T15:23:34.745926Z"
    },
    "code_folding": [
     11
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: lakefs://server/knn/pipeline.pkl\n",
      "Data: {\"id\": 25, \"x\": 3.98480486869812, \"y\": 5.40690803527832, \"z\": 2.577237367630005, \"vx\": -38.74491882324219, \"vy\": -152.4074249267578, \"vz\": -92.90726470947266, \"E\": -113632.3203125, \"L\": 493.3162536621094, \"Lz\": -397.8236389160156, \"FeH\": -1.180760145187378, \"knn\": [3, 26, 23]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  id</th><th style=\"text-align: right;\">     x</th><th style=\"text-align: right;\">      y</th><th style=\"text-align: right;\">      z</th><th style=\"text-align: right;\">      vx</th><th style=\"text-align: right;\">      vy</th><th style=\"text-align: right;\">      vz</th><th style=\"text-align: right;\">      E</th><th style=\"text-align: right;\">      L</th><th style=\"text-align: right;\">      Lz</th><th style=\"text-align: right;\">     FeH</th><th>knn                              </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">  25</td><td style=\"text-align: right;\">3.9848</td><td style=\"text-align: right;\">5.40691</td><td style=\"text-align: right;\">2.57724</td><td style=\"text-align: right;\">-38.7449</td><td style=\"text-align: right;\">-152.407</td><td style=\"text-align: right;\">-92.9073</td><td style=\"text-align: right;\">-113632</td><td style=\"text-align: right;\">493.316</td><td style=\"text-align: right;\">-397.824</td><td style=\"text-align: right;\">-1.18076</td><td>array([ 3, 26, 23], dtype=uint64)</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    id       x        y        z        vx        vy        vz        E        L        Lz       FeH  knn\n",
       "  0    25  3.9848  5.40691  2.57724  -38.7449  -152.407  -92.9073  -113632  493.316  -397.824  -1.18076  array([ 3, 26, 23], dtype=uint64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import vaex\n",
    "import hnswlib\n",
    "\n",
    "df = vaex.example()\n",
    "features = df.get_column_names(regex='^(?!id|\\\\.).*')  # not the id\n",
    "\n",
    "p = hnswlib.Index(space='l2', dim=df.shape[1] - 1)  # possible options are l2, cosine or ip\n",
    "p.init_index(max_elements=len(df), ef_construction=200, M=16)\n",
    "features = df.get_column_names(regex='^(?!id|\\\\.).*')  # not the id\n",
    "for i1, i2, chunk in df.to_pandas_df(chunk_size=10000):\n",
    "    X = chunk[features]\n",
    "    y = chunk['id']\n",
    "    p.add_items(X, y)\n",
    "\n",
    "p.set_ef(50)  # ef should always be > k (Controlling the recall by setting ef)\n",
    "\n",
    "@vaex.register_function(on_expression=False)\n",
    "def topk(*columns, k=3):\n",
    "    labels, _ = p.knn_query(np.array(columns).T, k=k)\n",
    "    return np.array(labels)\n",
    "\n",
    "df['knn'] = df.func.topk(*tuple([df[col] for col in features]), k=3)\n",
    "df.add_function('topk',topk)\n",
    "pipeline = Pipeline.from_dataframe(df)\n",
    "path = 'lakefs://server/knn/pipeline.pkl'\n",
    "data = df.gl.to_records(8)\n",
    "lakefs_commit(pipeline,path)\n",
    "print(f\"Path: {path}\\nData: {json.dumps(data)}\")\n",
    "pipeline.inference(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-singing",
   "metadata": {},
   "source": [
    "## Third data scietist build a recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.branches.create_branch(repository='server',  \\\n",
    "#  branch_creation=models.BranchCreation(name='recommender', source='main'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "disabled-architect",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T15:30:27.377572Z",
     "start_time": "2021-09-13T15:29:57.926689Z"
    },
    "code_folding": [
     66,
     76
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: lakefs://server/recommender/pipeline.pkl\n",
      "Data: {\"userId\": [1, 2, 3]}\n",
      "Columns: userId,als,tfidf,explanation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  userId</th><th>als                                                </th><th>tfidf                                              </th><th>explanation                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">       1</td><td>&quot;[&#x27;Videodrome&#x27;, &#x27;Deep Red (Profondo rosso)&#x27;, &#x27;Be...</td><td>&quot;[&#x27;Matrix, The&#x27;, &#x27;Star Wars: Episode IV - A New ...</td><td>&quot;[&#x27;Spider-Man 2&#x27;, &#x27;Freaks&#x27;, &#x27;Lord of the Rings: ...</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i></td><td style=\"text-align: right;\">       2</td><td>&quot;[&#x27;Mummy, The&#x27;, &#x27;Tingler, The&#x27;, &#x27;Children of the...</td><td>&quot;[&#x27;Raiders of the Lost Ark (Indiana Jones and th...</td><td>&quot;[&#x27;Time Machine, The&#x27;, &#x27;Creature from the Black ...</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>2</i></td><td style=\"text-align: right;\">       3</td><td>&quot;[&#x27;Wing Commander&#x27;, &#x27;Red Sonja&#x27;, &#x27;No Escape&#x27;, &#x27;A...</td><td>&quot;[&#x27;Aliens&#x27;, &#x27;Monty Python and the Holy Grail&#x27;, &#x27;...</td><td>&quot;[&#x27;M*A*S*H (a.k.a. MASH)&#x27;, &#x27;Trading Places&#x27;, &#x27;Sp...</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    userId  als                                                  tfidf                                                explanation\n",
       "  0         1  \"['Videodrome', 'Deep Red (Profondo rosso)', 'Be...  \"['Matrix, The', 'Star Wars: Episode IV - A New ...  \"['Spider-Man 2', 'Freaks', 'Lord of the Rings: ...\n",
       "  1         2  \"['Mummy, The', 'Tingler, The', 'Children of the...  \"['Raiders of the Lost Ark (Indiana Jones and th...  \"['Time Machine, The', 'Creature from the Black ...\n",
       "  2         3  \"['Wing Commander', 'Red Sonja', 'No Escape', 'A...  \"['Aliens', 'Monty Python and the Holy Grail', '...  \"['M*A*S*H (a.k.a. MASH)', 'Trading Places', 'Sp..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from random import choice\n",
    "\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pytest\n",
    "import vaex\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.nearest_neighbours import (\n",
    "    BM25Recommender,\n",
    "    CosineRecommender,\n",
    "    TFIDFRecommender,\n",
    "    bm25_weight,\n",
    "    )\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "df = vaex.open('../datasets/imdb.hdf5')\n",
    "counts = df['movieId'].value_counts()\n",
    "counts = counts[counts > 100]\n",
    "df = df[df['movieId'].isin(counts.index)]  # popular movies\n",
    "unique_movies = df.groupby(['movieId', 'genres']).agg({'title': 'count'})\n",
    "genres = {movie: genres for movie, genres in\n",
    "          zip(unique_movies['movieId'].tolist(), unique_movies['genres'].tolist())}\n",
    "unique_movies = df.groupby(['movieId', 'title']).agg({'count': 'count'})\n",
    "titles = {movie: name for movie, name in\n",
    "          zip(unique_movies['movieId'].tolist(), unique_movies['title'].tolist())}\n",
    "\n",
    "min_rating = 4.0\n",
    "df = df[min_rating < df['rating']]  # liked movies\n",
    "ratings = csr_matrix((np.ones(len(df)), (df['movieId'].values, df['userId'].values)))\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "\n",
    "mean_rating = df['rating'].mean()\n",
    "weighted = (bm25_weight(ratings, B=0.9) * 5).tocsr()\n",
    "\n",
    "als = AlternatingLeastSquares(factors=32)\n",
    "# als.fit(weighted)\n",
    "with open('../tests/models/als.pkl', 'rb') as handle:\n",
    "    als = pickle.load(handle)\n",
    "\n",
    "tfidf = TFIDFRecommender()\n",
    "# tfidf.fit(ratings)\n",
    "with open('../tests/models/tfidf.pkl', 'rb') as handle:\n",
    "    tfidf = pickle.load(handle)\n",
    "\n",
    "users = df['userId'].unique()\n",
    "user_items = ratings.T.tocsr()\n",
    "\n",
    "userid = choice(users)\n",
    "user_history = user_items.getrow(userid).indices\n",
    "recommendations = als.recommend(userid, user_items, N=10, filter_already_liked_items=True)\n",
    "\n",
    "\n",
    "@vaex.register_function()\n",
    "def recommend_als(ar, topk=5, filter_already_liked_items=True):\n",
    "    ret = []\n",
    "    for user in ar:\n",
    "        recommendations = als.recommend(user, user_items, N=topk,\n",
    "                                        filter_already_liked_items=filter_already_liked_items)\n",
    "        recommendation = [titles.get(recommendation[0]) for recommendation in recommendations]\n",
    "        ret.append(recommendation)\n",
    "    return pa.array(ret)\n",
    "\n",
    "@vaex.register_function()\n",
    "def recommend_tfidf(ar, topk=5, filter_already_liked_items=True):\n",
    "    ret = []\n",
    "    for user in ar:\n",
    "        recommendations = tfidf.recommend(user, user_items, N=topk,\n",
    "                                       filter_already_liked_items=filter_already_liked_items)\n",
    "        recommendation = [titles.get(recommendation[0]) for recommendation in recommendations]\n",
    "        ret.append(recommendation)\n",
    "    return pa.array(ret)\n",
    "\n",
    "@vaex.register_function(on_expression=False)\n",
    "def explain(users, items):\n",
    "    ret = []\n",
    "    for user,item in zip(users,items):\n",
    "        score_explained, contributions, W = als.explain(user, user_items, itemid=item)\n",
    "        items = [i for i, _ in contributions]\n",
    "        ret.append([titles.get(i) for i in items])\n",
    "    return pa.array(ret)\n",
    "\n",
    "df.add_function('recommend_als', recommend_als)\n",
    "df.add_function('recommend_tfidf', recommend_tfidf)\n",
    "df.add_function('explain', explain)\n",
    "\n",
    "df['als'] = df['userId'].recommend_als()\n",
    "df['tfidf'] = df['userId'].recommend_tfidf()\n",
    "df['explanation'] = df.func.explain(df['userId'],df['movieId'])\n",
    "\n",
    "\n",
    "pipeline = Pipeline.from_dataframe(df)\n",
    "path = 'lakefs://server/recommender/pipeline.pkl'\n",
    "lakefs_commit(pipeline,path)\n",
    "data = {'userId': [1, 2, 3]}\n",
    "columns = ['userId','als','tfidf','explanation']\n",
    "print(f\"Path: {path}\\nData: {json.dumps(data)}\\nColumns: {','.join(columns)}\")\n",
    "pipeline.inference(data,columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-hurricane",
   "metadata": {},
   "source": [
    "#### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "loaded-cartoon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T10:57:00.278668Z",
     "start_time": "2021-09-14T10:56:58.166654Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th>text                                               </th><th>organisations  </th><th>money                           </th><th>vector                                             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td>&#x27;Net income was $9.4 million compared to the pri...</td><td>[&#x27;Apple&#x27;]      </td><td>[&#x27;$9.4 million&#x27;, &#x27;$2.7 million&#x27;]</td><td>&#x27;array([ 0.46828035,  0.3082057 ,  0.40490758, -...</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i></td><td>&#x27;IBM had their revenue exceeded twelve billion d...</td><td>[&#x27;IBM&#x27;]        </td><td>[&#x27;twelve billion dollars&#x27;, &#x27;1b&#x27;]</td><td>&#x27;array([ 5.34848511e-01,  3.95896435e-01, -3.327...</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #  text                                                 organisations    money                             vector\n",
       "  0  'Net income was $9.4 million compared to the pri...  ['Apple']        ['$9.4 million', '$2.7 million']  'array([ 0.46828035,  0.3082057 ,  0.40490758, -...\n",
       "  1  'IBM had their revenue exceeded twelve billion d...  ['IBM']          ['twelve billion dollars', '1b']  'array([ 5.34848511e-01,  3.95896435e-01, -3.327..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spacy \n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import spacy\n",
    "import vaex\n",
    "from spacy.cli import download\n",
    "from spacy.language import Language\n",
    "from lakeml.vaex import Pipeline\n",
    "\n",
    "\n",
    "def download_nlp(lang='en_core_web_sm'):\n",
    "    try:\n",
    "        nlp = spacy.load(lang)\n",
    "        return True\n",
    "    except:\n",
    "        download(lang)\n",
    "    return False\n",
    "\n",
    "download_nlp()\n",
    "\n",
    "# Build a spacy entities pipeline\n",
    "@Language.component(\"ents\")\n",
    "def ents(doc):\n",
    "    return doc.ents\n",
    "\n",
    "nlp_entitie = spacy.load('en_core_web_sm')\n",
    "nlp_entitie.add_pipe('ents', name='ents', last=True)\n",
    "\n",
    "texts = [\n",
    "    \"Net income was $9.4 million compared to the prior year of $2.7 million. Apple is doing very well\",\n",
    "    \"IBM had their revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
    "]\n",
    "\n",
    "df = vaex.from_arrays(text=texts)\n",
    "\n",
    "@vaex.register_function()\n",
    "def entities(ar, label='ORG'):\n",
    "    if not isinstance(ar, list):\n",
    "        ar = ar.tolist()\n",
    "    docs = [nlp_entitie(doc) for doc in ar]\n",
    "    entities = [[str(ent.text) for ent in doc if ent.label_ == label] for doc in docs]\n",
    "    return pa.array(entities)\n",
    "\n",
    "df['organisations'] = df.text.entities(label='ORG')\n",
    "df['money'] = df.text.entities(label='MONEY')\n",
    "\n",
    "@Language.component(\"vectorize\")\n",
    "def vectorize(doc):\n",
    "    return doc.vector\n",
    "\n",
    "nlp_vectorize = spacy.load('en_core_web_sm', disable=[\"ner\", 'parser'])\n",
    "nlp_vectorize.add_pipe('vectorize', name='vectorize', last=True)\n",
    "\n",
    "@vaex.register_function()\n",
    "def to_vector(ar):\n",
    "    if not isinstance(ar, list):\n",
    "        ar = ar.tolist()\n",
    "    ret = np.array([nlp_vectorize(doc) for doc in ar])\n",
    "    return ret\n",
    "\n",
    "df.add_function('entities', entities)\n",
    "df.add_function('vectorize', vectorize)\n",
    "df.add_function('to_vector', to_vector)\n",
    "\n",
    "df['vector'] = df.text.to_vector()\n",
    "\n",
    "# pipeline = Pipeline.from_dataframe(df)\n",
    "# path = 'lakefs://server/spacy/pipeline.pkl'\n",
    "# lakefs_commit(pipeline,path)\n",
    "# data = {'text': ['Apple and Microsoft are trying a Billion dollar project together']}\n",
    "# columns = ['userId','als','tfidf','explanation']\n",
    "# print(f\"Path: {path}\\nData: {json.dumps(data)}\")\n",
    "# pipeline.inference(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "flexible-recipient",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T10:57:31.926069Z",
     "start_time": "2021-09-14T10:57:22.661178Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th>text                                               </th><th>results                                           </th><th>label   </th><th style=\"text-align: right;\">   score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td>&#x27;We are very happy to include pipeline into the ...</td><td>{&#x27;label&#x27;: &#x27;POSITIVE&#x27;, &#x27;score&#x27;: 0.9978193640708923}</td><td>POSITIVE</td><td style=\"text-align: right;\">0.997819</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i></td><td>ths is real                                        </td><td>{&#x27;label&#x27;: &#x27;POSITIVE&#x27;, &#x27;score&#x27;: 0.9997795820236206}</td><td>POSITIVE</td><td style=\"text-align: right;\">0.99978 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #  text                                                 results                                             label        score\n",
       "  0  'We are very happy to include pipeline into the ...  {'label': 'POSITIVE', 'score': 0.9978193640708923}  POSITIVE  0.997819\n",
       "  1  ths is real                                          {'label': 'POSITIVE', 'score': 0.9997795820236206}  POSITIVE  0.99978"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huggingface \n",
    "\n",
    "import pyarrow as pa\n",
    "import vaex\n",
    "from transformers import pipeline as hf_pipeline\n",
    "\n",
    "classifier = hf_pipeline('sentiment-analysis')\n",
    "\n",
    "@vaex.register_function()\n",
    "def sentiment(ar):\n",
    "    if isinstance(ar, str):\n",
    "        ar = [ar]\n",
    "    return pa.array(classifier(ar.tolist()))\n",
    "\n",
    "df = vaex.from_arrays(text=['We are very happy to include pipeline into the transformers repository.',\n",
    "                            'ths is real'])\n",
    "df.add_function('sentiment', sentiment)\n",
    "df['results'] = df.text.sentiment()\n",
    "df['label'] = df['results'].apply(lambda x: x.get('label') if isinstance(x, dict) else None,\n",
    "                                  vectorize=False)\n",
    "df['score'] = df['results'].apply(lambda x: x.get('score') if isinstance(x, dict) else None, vectorize=False)\n",
    "\n",
    "# pipeline = Pipeline.from_dataframe(df)\n",
    "# data ={'text': 'this is my life, and I love it'}\n",
    "# path = 'lakefs://server/hf/pipeline.pkl'\n",
    "# lakefs_commit(pipeline, path)\n",
    "# print(f\"Path: {path}\\nData: {json.dumps(data)}\")\n",
    "# pipeline.inference(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "possible-gates",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T08:40:31.707319Z",
     "start_time": "2021-09-22T08:40:21.617333Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 09-22 10:40:21] {1431} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 09-22 10:40:21] {1477} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl: 09-22 10:40:22] {1514} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'lrl1']\n",
      "[flaml.automl: 09-22 10:40:22] {1746} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 09-22 10:40:22] {1931} INFO -  at 0.5s,\tbest lgbm's error=0.0134,\tbest lgbm's error=0.0134\n",
      "[flaml.automl: 09-22 10:40:22] {1746} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 09-22 10:40:22] {1931} INFO -  at 0.6s,\tbest lgbm's error=0.0134,\tbest lgbm's error=0.0134\n",
      "[flaml.automl: 09-22 10:40:22] {1746} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 09-22 10:40:22] {1931} INFO -  at 0.6s,\tbest lgbm's error=0.0134,\tbest lgbm's error=0.0134\n",
      "[flaml.automl: 09-22 10:40:22] {1746} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 09-22 10:40:22] {1931} INFO -  at 0.7s,\tbest lgbm's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:22] {1746} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl: 09-22 10:40:22] {1931} INFO -  at 0.7s,\tbest xgboost's error=0.0134,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:22] {1746} INFO - iteration 5, current learner extra_tree\n",
      "[flaml.automl: 09-22 10:40:22] {1931} INFO -  at 1.1s,\tbest extra_tree's error=0.0507,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:22] {1746} INFO - iteration 6, current learner rf\n",
      "[flaml.automl: 09-22 10:40:23] {1931} INFO -  at 1.4s,\tbest rf's error=0.0256,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:23] {1746} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 09-22 10:40:23] {1931} INFO -  at 1.5s,\tbest lgbm's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:23] {1746} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 09-22 10:40:23] {1931} INFO -  at 1.5s,\tbest lgbm's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:23] {1746} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 09-22 10:40:23] {1931} INFO -  at 1.6s,\tbest lgbm's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:23] {1746} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 09-22 10:40:23] {1931} INFO -  at 1.8s,\tbest lgbm's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:23] {1746} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 09-22 10:40:23] {1931} INFO -  at 1.8s,\tbest xgboost's error=0.0134,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:23] {1746} INFO - iteration 12, current learner rf\n",
      "[flaml.automl: 09-22 10:40:23] {1931} INFO -  at 2.2s,\tbest rf's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:23] {1746} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 09-22 10:40:23] {1931} INFO -  at 2.2s,\tbest xgboost's error=0.0134,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:23] {1746} INFO - iteration 14, current learner rf\n",
      "[flaml.automl: 09-22 10:40:24] {1931} INFO -  at 2.5s,\tbest rf's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:24] {1746} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 09-22 10:40:24] {1931} INFO -  at 2.6s,\tbest xgboost's error=0.0134,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:24] {1746} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 09-22 10:40:24] {1931} INFO -  at 2.9s,\tbest lgbm's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:24] {1746} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 09-22 10:40:24] {1931} INFO -  at 3.2s,\tbest extra_tree's error=0.0055,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:24] {1746} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 09-22 10:40:25] {1931} INFO -  at 3.4s,\tbest lgbm's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:25] {1746} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 09-22 10:40:25] {1931} INFO -  at 3.4s,\tbest xgboost's error=0.0071,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:25] {1746} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 09-22 10:40:25] {1931} INFO -  at 3.5s,\tbest xgboost's error=0.0071,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:25] {1746} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 09-22 10:40:25] {1931} INFO -  at 3.6s,\tbest xgboost's error=0.0071,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:25] {1746} INFO - iteration 22, current learner rf\n",
      "[flaml.automl: 09-22 10:40:25] {1931} INFO -  at 4.0s,\tbest rf's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:25] {1746} INFO - iteration 23, current learner rf\n",
      "[flaml.automl: 09-22 10:40:26] {1931} INFO -  at 4.4s,\tbest rf's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:26] {1746} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl: 09-22 10:40:26] {1931} INFO -  at 4.7s,\tbest extra_tree's error=0.0055,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:26] {1746} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 09-22 10:40:26] {1931} INFO -  at 5.1s,\tbest extra_tree's error=0.0055,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:26] {1746} INFO - iteration 26, current learner rf\n",
      "[flaml.automl: 09-22 10:40:27] {1931} INFO -  at 5.6s,\tbest rf's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:27] {1746} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 09-22 10:40:27] {1931} INFO -  at 5.6s,\tbest xgboost's error=0.0071,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:27] {1746} INFO - iteration 28, current learner catboost\n",
      "[flaml.automl: 09-22 10:40:27] {1931} INFO -  at 5.9s,\tbest catboost's error=0.0067,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:27] {1746} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 09-22 10:40:27] {1931} INFO -  at 6.2s,\tbest extra_tree's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:27] {1746} INFO - iteration 30, current learner extra_tree\n",
      "[flaml.automl: 09-22 10:40:28] {1931} INFO -  at 6.5s,\tbest extra_tree's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:28] {1746} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 09-22 10:40:28] {1931} INFO -  at 6.9s,\tbest lgbm's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:28] {1746} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl: 09-22 10:40:28] {1931} INFO -  at 7.2s,\tbest lgbm's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:28] {1746} INFO - iteration 33, current learner rf\n",
      "[flaml.automl: 09-22 10:40:29] {1931} INFO -  at 7.6s,\tbest rf's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:29] {1746} INFO - iteration 34, current learner extra_tree\n",
      "[flaml.automl: 09-22 10:40:29] {1931} INFO -  at 7.9s,\tbest extra_tree's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:29] {1746} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl: 09-22 10:40:29] {1931} INFO -  at 8.1s,\tbest lgbm's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:29] {1746} INFO - iteration 36, current learner catboost\n",
      "[flaml.automl: 09-22 10:40:29] {1931} INFO -  at 8.2s,\tbest catboost's error=0.0067,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:29] {1746} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 09-22 10:40:30] {1931} INFO -  at 8.5s,\tbest extra_tree's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:30] {1746} INFO - iteration 38, current learner catboost\n",
      "[flaml.automl: 09-22 10:40:30] {1931} INFO -  at 8.5s,\tbest catboost's error=0.0067,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:30] {1746} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl: 09-22 10:40:30] {1931} INFO -  at 8.6s,\tbest xgboost's error=0.0071,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:30] {1746} INFO - iteration 40, current learner catboost\n",
      "[flaml.automl: 09-22 10:40:30] {1931} INFO -  at 8.7s,\tbest catboost's error=0.0067,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:30] {1746} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl: 09-22 10:40:30] {1931} INFO -  at 8.8s,\tbest xgboost's error=0.0004,\tbest lgbm's error=0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 09-22 10:40:30] {1746} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl: 09-22 10:40:30] {1931} INFO -  at 9.0s,\tbest xgboost's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:30] {1746} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl: 09-22 10:40:30] {1931} INFO -  at 9.3s,\tbest lgbm's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:30] {1746} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl: 09-22 10:40:31] {1931} INFO -  at 9.4s,\tbest xgboost's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:31] {1746} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 09-22 10:40:31] {1931} INFO -  at 9.5s,\tbest extra_tree's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:31] {1746} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl: 09-22 10:40:31] {1931} INFO -  at 9.8s,\tbest xgboost's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:31] {1746} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl: 09-22 10:40:31] {1931} INFO -  at 9.9s,\tbest xgboost's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:31] {1746} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl: 09-22 10:40:31] {1931} INFO -  at 10.0s,\tbest lgbm's error=0.0004,\tbest lgbm's error=0.0004\n",
      "[flaml.automl: 09-22 10:40:31] {2032} INFO - selected model: LGBMClassifier(colsample_bytree=0.9285002286474459,\n",
      "               learning_rate=0.2712162364070373, max_bin=512,\n",
      "               min_child_samples=15, n_estimators=12, num_leaves=4,\n",
      "               objective='multiclass', reg_alpha=0.002668211515123386,\n",
      "               reg_lambda=0.5215467339232843, verbose=-1)\n",
      "[flaml.automl: 09-22 10:40:31] {2101} INFO - not retraining because the time budget is too small.\n",
      "[flaml.automl: 09-22 10:40:31] {1538} INFO - fit succeeded\n",
      "[flaml.automl: 09-22 10:40:31] {1540} INFO - Time taken to find the best model: 0.6848530769348145\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4e165179401e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m automl.fit(train[features].values, y_train=train[target].values,\n\u001b[1;32m     23\u001b[0m            **automl_settings)\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# Export the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Auto ML\n",
    "import vaex\n",
    "import numpy as np\n",
    "from vaex.ml.lightgbm import LightGBMModel\n",
    "from vaex.ml.sklearn import Predictor\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import json\n",
    "train, test = vaex.ml.datasets.load_iris_1e5().ml.train_test_split(test_size=0.2, verbose=False)\n",
    "features = ['petal_length', 'petal_width', 'sepal_length', 'sepal_width']\n",
    "target = 'class_'\n",
    "\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "automl_settings = {\n",
    "    \"time_budget\": 10,  # in seconds\n",
    "    \"metric\": 'accuracy',\n",
    "    \"task\": 'classification'\n",
    "}\n",
    "\n",
    "\n",
    "automl.fit(train[features].values, y_train=train[target].values,\n",
    "           **automl_settings)\n",
    "print(automl.predict_proba(X_train).shape)\n",
    "# Export the best model\n",
    "print(automl.model)\n",
    "\n",
    "# model = Predictor(model=automl, features=features, target=target)\n",
    "model.fit(train, )\n",
    "# print(automl.predict_proba(X_train).shape)\n",
    "# Export the best model\n",
    "# print(automl.model)\n",
    "\n",
    "# booster = LightGBMModel(features=features, \n",
    "#                         target=target,                         \n",
    "#                         prediction_name='lgm_predictions', \n",
    "#                         num_boost_round=500, params={'verbose': -1,\n",
    "#                                                      'objective':'multiclass',\n",
    "#                                                     'num_class':3})\n",
    "# booster.fit(train)\n",
    "# train = booster.transform(train)\n",
    "\n",
    "# @vaex.register_function()\n",
    "# def argmax(ar, axis=1):\n",
    "#     return np.argmax(ar,axis=axis)\n",
    "\n",
    "# train.add_function('argmax',argmax)\n",
    "# train['prediction'] = train['lgm_predictions'].argmax()\n",
    "\n",
    "# pipeline = Pipeline.from_dataframe(train)\n",
    "# pipeline.set_variable('accuracy', accuracy_score(pipeline.inference(test[features])['prediction'].values, test[target].values))\n",
    "# path = 'lakefs://server/lightgbm/pipeline.pkl'\n",
    "# data = test.gl.to_records(0)\n",
    "# lakefs_commit(pipeline, path) # commit\n",
    "# print(f\"Path: {path}\\nData: {json.dumps(data)}\")\n",
    "# pipeline.inference(test).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "liked-neutral",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T15:45:40.165288Z",
     "start_time": "2021-09-13T15:45:40.162965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Deep leaarning - todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "female-tampa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T15:45:50.766962Z",
     "start_time": "2021-09-13T15:45:50.764370Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sklearn pipeline - todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-boards",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T15:42:38.555773Z",
     "start_time": "2021-09-13T15:42:27.199158Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# MLflow pipeline - todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-process",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "authentic-render",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Re-Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-awareness",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T17:32:18.907474Z",
     "start_time": "2021-04-07T17:32:17.493193Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fit(df):\n",
    "    print(\"FIT\")\n",
    "    import vaex\n",
    "    import numpy as np\n",
    "    from vaex.ml.lightgbm import LightGBMModel\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    \n",
    "    features = ['petal_length', 'petal_width', 'sepal_length', 'sepal_width']\n",
    "    target = 'class_'\n",
    "\n",
    "\n",
    "    booster = LightGBMModel(features=features, \n",
    "                            target=target,                         \n",
    "                            prediction_name='lgm_predictions', \n",
    "                            num_boost_round=500, params={'verbose': -1,\n",
    "                                                         'objective':'multiclass',\n",
    "                                                        'num_class':3})\n",
    "    booster.fit(df)\n",
    "    df = booster.transform(df)\n",
    "\n",
    "    @vaex.register_function()\n",
    "    def argmax(ar, axis=1):\n",
    "        return np.argmax(ar,axis=axis)\n",
    "\n",
    "    df.add_function('argmax',argmax)\n",
    "    df['prediction'] = df['lgm_predictions'].argmax()\n",
    "    return df\n",
    "\n",
    "train, test = vaex.ml.datasets.load_iris_1e5().ml.train_test_split(test_size=0.2, verbose=False)\n",
    "pipeline = Pipeline.from_dataframe(train, fit=fit)\n",
    "pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-johnson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T17:32:25.120111Z",
     "start_time": "2021-04-07T17:32:25.041735Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipeline.inference(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-commercial",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
