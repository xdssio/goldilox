{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "497cd473",
   "metadata": {},
   "source": [
    "# Online learning benchmarks\n",
    "\n",
    "* [LightGBM](https://lightgbm.readthedocs.io/en/latest/)\n",
    "* [XGBoost](https://xgboost.readthedocs.io/en/stable/)\n",
    "* [Catboost](https://catboost.ai)\n",
    "* [River](https://riverml.xyz/latest/)\n",
    "* [Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier.partial_fit)\n",
    "* [Vopal Wabbit](https://vowpalwabbit.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e30d80c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:01:56.029547Z",
     "start_time": "2021-12-14T16:01:54.214467Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000_000, n_informative=10, n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "895fcc7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:04:48.231767Z",
     "start_time": "2021-12-14T16:04:47.896868Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonatanalexander/development/xdss/goldilox/.venv/lib/python3.7/site-packages/vaex/ml/__init__.py:31: UserWarning: Make sure the DataFrame is shuffled\n",
      "  warnings.warn('Make sure the DataFrame is shuffled')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  feature_0</th><th style=\"text-align: right;\">  feature_1</th><th style=\"text-align: right;\">  feature_2</th><th style=\"text-align: right;\">  feature_3</th><th style=\"text-align: right;\">  feature_4</th><th style=\"text-align: right;\">  feature_5</th><th style=\"text-align: right;\">  feature_6</th><th style=\"text-align: right;\">  feature_7</th><th style=\"text-align: right;\">  feature_8</th><th style=\"text-align: right;\">  feature_9</th><th style=\"text-align: right;\">  feature_10</th><th style=\"text-align: right;\">  feature_11</th><th style=\"text-align: right;\">  feature_12</th><th style=\"text-align: right;\">  feature_13</th><th style=\"text-align: right;\">  feature_14</th><th style=\"text-align: right;\">  feature_15</th><th style=\"text-align: right;\">  feature_16</th><th style=\"text-align: right;\">  feature_17</th><th style=\"text-align: right;\">  feature_18</th><th style=\"text-align: right;\">  feature_19</th><th style=\"text-align: right;\">  target</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">  -0.134619</td><td style=\"text-align: right;\">  -0.210785</td><td style=\"text-align: right;\">  -1.27125 </td><td style=\"text-align: right;\">   0.319068</td><td style=\"text-align: right;\">  -0.506557</td><td style=\"text-align: right;\">  -0.903006</td><td style=\"text-align: right;\">   1.43086 </td><td style=\"text-align: right;\">  0.354004 </td><td style=\"text-align: right;\">   1.44165 </td><td style=\"text-align: right;\">   2.37896 </td><td style=\"text-align: right;\">    0.621935</td><td style=\"text-align: right;\">   -0.235586</td><td style=\"text-align: right;\">    0.971325</td><td style=\"text-align: right;\">    -3.17172</td><td style=\"text-align: right;\">    -1.69216</td><td style=\"text-align: right;\">     1.64932</td><td style=\"text-align: right;\">   -1.33266 </td><td style=\"text-align: right;\">    0.131078</td><td style=\"text-align: right;\">    -1.84336</td><td style=\"text-align: right;\">    0.775879</td><td style=\"text-align: right;\">       3</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i></td><td style=\"text-align: right;\">  -1.09678 </td><td style=\"text-align: right;\">   1.11236 </td><td style=\"text-align: right;\">  -0.124019</td><td style=\"text-align: right;\">   1.20753 </td><td style=\"text-align: right;\">   0.754969</td><td style=\"text-align: right;\">  -1.32046 </td><td style=\"text-align: right;\">   0.075942</td><td style=\"text-align: right;\">  0.0368741</td><td style=\"text-align: right;\">  -0.923697</td><td style=\"text-align: right;\">  -0.138596</td><td style=\"text-align: right;\">    2.05469 </td><td style=\"text-align: right;\">   -2.11743 </td><td style=\"text-align: right;\">    1.14415 </td><td style=\"text-align: right;\">     2.20503</td><td style=\"text-align: right;\">     1.74582</td><td style=\"text-align: right;\">    -3.21001</td><td style=\"text-align: right;\">    0.381363</td><td style=\"text-align: right;\">   -0.108705</td><td style=\"text-align: right;\">     0.32164</td><td style=\"text-align: right;\">    1.94967 </td><td style=\"text-align: right;\">       3</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    feature_0    feature_1    feature_2    feature_3    feature_4    feature_5    feature_6    feature_7    feature_8    feature_9    feature_10    feature_11    feature_12    feature_13    feature_14    feature_15    feature_16    feature_17    feature_18    feature_19    target\n",
       "  0    -0.134619    -0.210785    -1.27125      0.319068    -0.506557    -0.903006     1.43086     0.354004      1.44165      2.37896       0.621935     -0.235586      0.971325      -3.17172      -1.69216       1.64932     -1.33266       0.131078      -1.84336      0.775879         3\n",
       "  1    -1.09678      1.11236     -0.124019     1.20753      0.754969    -1.32046      0.075942    0.0368741    -0.923697    -0.138596      2.05469      -2.11743       1.14415        2.20503       1.74582      -3.21001      0.381363     -0.108705       0.32164      1.94967          3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vaex\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "target = 'target'\n",
    "features = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "df = vaex.from_dict({feature: X[:,i] for i,feature in enumerate(features)})\n",
    "df['target'] = y+1\n",
    "\n",
    "train, test = df.ml.train_test_split()\n",
    "\n",
    "validation = train.head(10)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff960ec",
   "metadata": {},
   "source": [
    "## River"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c6a473f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:16:36.374287Z",
     "start_time": "2021-12-14T16:16:35.058685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cda070f8284f62a9238f86317c933d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), Label(value='In progress...')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy River: 0.60005625\n"
     ]
    }
   ],
   "source": [
    "from vaex.ml.incubator.river import RiverModel\n",
    "import vaex.ml.metrics\n",
    "from river.linear_model import LogisticRegression\n",
    "from river import optim\n",
    "from river.multiclass import OneVsRestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set up the model\n",
    "model = RiverModel(model = OneVsRestClassifier(LogisticRegression()),\n",
    "                   batch_size=11_000_000,\n",
    "                   features=features, \n",
    "                   target=target, \n",
    "                   prediction_name='river')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train, progress='widget')\n",
    "train = model.transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb18219",
   "metadata": {},
   "source": [
    "# VW\n",
    "* https://mlcourse.ai/articles/topic8-sgd-vw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30fdc474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:09:09.420869Z",
     "start_time": "2021-12-14T16:09:09.233164Z"
    },
    "code_folding": [
     18
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  feature_0</th><th style=\"text-align: right;\">  feature_1</th><th style=\"text-align: right;\">  feature_2</th><th style=\"text-align: right;\">  feature_3</th><th style=\"text-align: right;\">  feature_4</th><th style=\"text-align: right;\">  feature_5</th><th style=\"text-align: right;\">  feature_6</th><th style=\"text-align: right;\">  feature_7</th><th style=\"text-align: right;\">  feature_8</th><th style=\"text-align: right;\">  feature_9</th><th style=\"text-align: right;\">  feature_10</th><th style=\"text-align: right;\">  feature_11</th><th style=\"text-align: right;\">  feature_12</th><th style=\"text-align: right;\">  feature_13</th><th style=\"text-align: right;\">  feature_14</th><th style=\"text-align: right;\">  feature_15</th><th style=\"text-align: right;\">  feature_16</th><th style=\"text-align: right;\">  feature_17</th><th style=\"text-align: right;\">  feature_18</th><th style=\"text-align: right;\">  feature_19</th><th style=\"text-align: right;\">  target</th><th style=\"text-align: right;\">  vw</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">    1.09626</td><td style=\"text-align: right;\">   -1.67528</td><td style=\"text-align: right;\">  -0.916187</td><td style=\"text-align: right;\">  -0.671703</td><td style=\"text-align: right;\">  -4.26103 </td><td style=\"text-align: right;\">   0.730177</td><td style=\"text-align: right;\">    3.24956</td><td style=\"text-align: right;\"> -0.0408016</td><td style=\"text-align: right;\">   -1.74192</td><td style=\"text-align: right;\">    1.78474</td><td style=\"text-align: right;\">    -4.34423</td><td style=\"text-align: right;\">   -1.54608 </td><td style=\"text-align: right;\">    0.524216</td><td style=\"text-align: right;\">     5.84992</td><td style=\"text-align: right;\">     2.12973</td><td style=\"text-align: right;\">    -1.25836</td><td style=\"text-align: right;\">    3.78808 </td><td style=\"text-align: right;\">     1.56126</td><td style=\"text-align: right;\">    -1.92343</td><td style=\"text-align: right;\">   2.44382  </td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">   2</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i></td><td style=\"text-align: right;\">   -1.62342</td><td style=\"text-align: right;\">   -1.51648</td><td style=\"text-align: right;\">   0.199182</td><td style=\"text-align: right;\">   0.922495</td><td style=\"text-align: right;\">  -0.707596</td><td style=\"text-align: right;\">   0.757213</td><td style=\"text-align: right;\">    3.11861</td><td style=\"text-align: right;\">  1.07286  </td><td style=\"text-align: right;\">   -1.1791 </td><td style=\"text-align: right;\">    1.18565</td><td style=\"text-align: right;\">     1.9924 </td><td style=\"text-align: right;\">    0.525271</td><td style=\"text-align: right;\">    1.13078 </td><td style=\"text-align: right;\">    -0.99008</td><td style=\"text-align: right;\">    -1.85412</td><td style=\"text-align: right;\">     1.94633</td><td style=\"text-align: right;\">   -0.109579</td><td style=\"text-align: right;\">     1.44296</td><td style=\"text-align: right;\">    -1.049  </td><td style=\"text-align: right;\">  -0.0227364</td><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">   2</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    feature_0    feature_1    feature_2    feature_3    feature_4    feature_5    feature_6    feature_7    feature_8    feature_9    feature_10    feature_11    feature_12    feature_13    feature_14    feature_15    feature_16    feature_17    feature_18    feature_19    target    vw\n",
       "  0      1.09626     -1.67528    -0.916187    -0.671703    -4.26103      0.730177      3.24956   -0.0408016     -1.74192      1.78474      -4.34423     -1.54608       0.524216       5.84992       2.12973      -1.25836      3.78808        1.56126      -1.92343     2.44382           2     2\n",
       "  1     -1.62342     -1.51648     0.199182     0.922495    -0.707596     0.757213      3.11861    1.07286       -1.1791       1.18565       1.9924       0.525271      1.13078       -0.99008      -1.85412       1.94633     -0.109579       1.44296      -1.049      -0.0227364         1     2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import traitlets\n",
    "import tempfile\n",
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vowpalwabbit.DFtoVW import DFtoVW\n",
    "from vowpalwabbit.pyvw import vw\n",
    "from tqdm import tqdm\n",
    "\n",
    "params = {\"enable_logging\": True, 'oaa':3}\n",
    "model = vw(**params)\n",
    "\n",
    "for _,_,d in tqdm(train.head(1000).to_pandas_df(chunk_size=10)):\n",
    "    for ex in DFtoVW.from_colnames(df=d, y='target', x=features).convert_df():\n",
    "        model.learn(ex)\n",
    "\n",
    "model.finish()    \n",
    "\n",
    "class VWModell(traitlets.HasTraits):\n",
    "\n",
    "        # This should work with the reduce's arguments\n",
    "        def __init__(self, model=None, features=None, target=None, params=None):\n",
    "            self.params = params or {}\n",
    "            self.features = features\n",
    "            self.target = target            \n",
    "            self.model = self._decode_model(model)\n",
    "\n",
    "        # This is how you make a class pickalbe\n",
    "        def __reduce__(self):\n",
    "            return (self.__class__, (self._encode(), self.features, self.target, self.params))\n",
    "\n",
    "        # How vw implemented serialization\n",
    "        def _decode_model(self, encoding):       \n",
    "            if encoding is None:\n",
    "                return vw(**self.params)                \n",
    "            if isinstance(encoding, str):                \n",
    "                model_data = base64.decodebytes(encoding.encode('ascii'))\n",
    "                openfilename = tempfile.mktemp()\n",
    "                with open(openfilename, 'wb') as f:\n",
    "                    f.write(model_data)\n",
    "                params = self.params.copy()\n",
    "                params['i']= openfilename\n",
    "                return vw(**params)\n",
    "            else:\n",
    "                return encoding\n",
    "\n",
    "        # How vw implemented serialization\n",
    "        def _encode(self):\n",
    "            if isinstance(self.model, bytes):\n",
    "                return self.model\n",
    "            filename = tempfile.mktemp()\n",
    "            self.model.save(filename)\n",
    "            with open(filename, 'rb') as f:\n",
    "                model_data = f.read()\n",
    "            encoding =  base64.encodebytes(model_data).decode('ascii')\n",
    "            return encoding   \n",
    "        \n",
    "        def predict(self, data):   \n",
    "            if isinstance(data, vaex.dataframe.DataFrame):\n",
    "                data = data.to_pandas_df()\n",
    "            elif isinstance(data, np.ndarray):\n",
    "                data = pd.DataFrame(data, columns=features)  \n",
    "            if self.target not in data:                \n",
    "                data[self.target] = 1\n",
    "            examples = DFtoVW.from_colnames(df=data, y=target, x=features).convert_df()            \n",
    "            return np.array([self.model.predict(ex) for ex in examples])\n",
    "\n",
    "vw_model = VWModell(model=model, features=features, target=target, params=params)\n",
    "\n",
    "@vaex.register_function(on_expression=False)\n",
    "def predict_vw(*columns):\n",
    "    data = np.array(columns).T                \n",
    "    return np.array(vw_model.predict(data))\n",
    "\n",
    "train.add_function('predict_vw',predict_vw)\n",
    "train['vw'] = train.func.predict_vw(*features)\n",
    "print(f\"Accuracy VW: {accuracy_score(vw_model.predict(validation), validation[target].values)}\")\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7e664c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:00:31.275152Z",
     "start_time": "2021-12-14T17:00:31.263238Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train.head(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd7987",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c4a2963d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:01:11.038620Z",
     "start_time": "2021-12-14T17:00:57.319184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit(xgboost) [########################################] 100.00% elapsed time  :    13.70s =  0.2m =  0.0h \n",
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "n_samples = len(df)\n",
    "progressbar = vaex.utils.progressbars(True, title=\"fit(xgboost)\")\n",
    "num_epochs = 2\n",
    "batch_size = 1000\n",
    "\n",
    "model = None\n",
    "for epoch in range(num_epochs):\n",
    "    for i1, i2, chunks in train.evaluate_iterator(features+[target], chunk_size=batch_size, array_type='numpy'):\n",
    "        progressbar((n_samples * epoch + i1) / (num_epochs * n_samples))\n",
    "        X = np.array(chunks[:-1]).T  # the most efficient way depends on the algorithm (row of column based access)\n",
    "        y = np.array(chunks[-1], copy=False)\n",
    "        xgb_params = {\n",
    "            'update':'refresh',\n",
    "            'refresh_leaf': True,\n",
    "            'xgb_model':model,\n",
    "            'objective':'multi:softmax',\n",
    "            'num_class': 3,\n",
    "            'verbosity': 0}\n",
    "        model = XGBClassifier(**xgb_params)\n",
    "        model.fit(X, y)\n",
    "\n",
    "\n",
    "progressbar(1.0)\n",
    "\n",
    "xgb = Predictor(model=model,\n",
    "                features=features, \n",
    "                target=target,\n",
    "                prediction_name='xgb')\n",
    "train = xgb.transform(train)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c1f842",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:01:12.852706Z",
     "start_time": "2021-12-14T17:01:12.838852Z"
    }
   },
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "803a5f84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:10:07.193855Z",
     "start_time": "2021-12-14T17:10:06.652245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit(lgm) [########################################] 100.00% elapsed time  :     0.51s =  0.0m =  0.0h\n",
      " "
     ]
    }
   ],
   "source": [
    "from lightgbm.sklearn import LGBMClassifier\n",
    "\n",
    "n_samples = len(df)\n",
    "progressbar = vaex.utils.progressbars(True, title=\"fit(lgm)\")\n",
    "num_epochs = 2\n",
    "batch_size = 1000\n",
    "\n",
    "model = None\n",
    "\n",
    "params = {'verbosity': -1,\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 3,\n",
    "         'num_iterations':1}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i1, i2, chunks in train.evaluate_iterator(features+[target], chunk_size=batch_size, array_type='numpy'):\n",
    "        progressbar((n_samples * epoch + i1) / (num_epochs * n_samples))\n",
    "        X = np.array(chunks[:-1]).T  # the most efficient way depends on the algorithm (row of column based access)\n",
    "        y = np.array(chunks[-1], copy=False)\n",
    "\n",
    "        if model is None:\n",
    "            model = LGBMClassifier(**params)\n",
    "            model.fit(X, y)\n",
    "        else:            \n",
    "            model.fit(X, y, init_model=model) # TODO test\n",
    "\n",
    "\n",
    "progressbar(1.0)\n",
    "\n",
    "lgb = Predictor(model=model,\n",
    "                features=features, \n",
    "                target=target,\n",
    "                prediction_name='lgm')\n",
    "train = lgb.transform(train)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d30c4cb",
   "metadata": {},
   "source": [
    "# Catboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b5449168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:10:12.276848Z",
     "start_time": "2021-12-14T17:10:11.975983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit(catboost) [########################################] 100.00% elapsed time  :     0.28s =  0.0m =  0.0h\n",
      " "
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "n_samples = len(df)\n",
    "progressbar = vaex.utils.progressbars(True, title=\"fit(catboost)\")\n",
    "num_epochs = 2\n",
    "batch_size = 1000\n",
    "\n",
    "model = None\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i1, i2, chunks in train.evaluate_iterator(features+[target], chunk_size=batch_size, array_type='numpy'):\n",
    "        progressbar((n_samples * epoch + i1) / (num_epochs * n_samples))\n",
    "        X = np.array(chunks[:-1]).T  # the most efficient way depends on the algorithm (row of column based access)\n",
    "        y = np.array(chunks[-1], copy=False)\n",
    "        params = {'verbose': 0, 'iterations': 1,'objective': 'MultiClass'}\n",
    "        if model is None:\n",
    "            model = CatBoostClassifier(**params)\n",
    "            model.fit(X, y)\n",
    "        else:            \n",
    "            model.fit(X, y, init_model=model) # TODO test\n",
    "\n",
    "\n",
    "progressbar(1.0)\n",
    "\n",
    "cb = Predictor(model=model,\n",
    "                features=features, \n",
    "                target=target,\n",
    "                prediction_name='cb')\n",
    "train = cb.transform(train)   \n",
    "train['cb'] = train['cb'].apply(lambda x: x[0]) # catboost beeing annoying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137b9ddf",
   "metadata": {},
   "source": [
    "# SGD classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a2be5272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:22:43.959826Z",
     "start_time": "2021-12-14T17:22:43.872875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit(SGD) [########################################] 100.00% elapsed time  :     0.06s =  0.0m =  0.0h\n",
      " "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "n_samples = len(df)\n",
    "progressbar = vaex.utils.progressbars(True, title=\"fit(SGD)\")\n",
    "num_epochs = 2\n",
    "batch_size = 1000\n",
    "\n",
    "model = None\n",
    "\n",
    "model = SGDClassifier()\n",
    "for epoch in range(num_epochs):\n",
    "    for i1, i2, chunks in train.evaluate_iterator(features+[target], chunk_size=batch_size, array_type='numpy'):\n",
    "        progressbar((n_samples * epoch + i1) / (num_epochs * n_samples))\n",
    "        X = np.array(chunks[:-1]).T  # the most efficient way depends on the algorithm (row of column based access)\n",
    "        y = np.array(chunks[-1], copy=False)\n",
    "        if epoch==0 and i1==0:\n",
    "            model.fit(X, y)\n",
    "        else:\n",
    "            model.partial_fit(X, y) \n",
    "\n",
    "\n",
    "progressbar(1.0)\n",
    "\n",
    "sgd = Predictor(model=model,\n",
    "                features=features, \n",
    "                target=target,\n",
    "                prediction_name='sgd')\n",
    "train = sgd.transform(train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3c35b907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:22:47.302544Z",
     "start_time": "2021-12-14T17:22:46.735248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy River: 0.5942\n",
      "Accuracy XGBoost: 0.8628\n",
      "Accuracy LightGBM: 0.856\n",
      "Accuracy Catboost: 0.7844\n",
      "Accuracy Vopal Wabbit: 0.6676\n",
      "Accuracy SGD: 0.5676\n"
     ]
    }
   ],
   "source": [
    "y_true = train[target].values\n",
    "print(f\"Accuracy River: {accuracy_score(train['river'].values, y_true)}\")\n",
    "print(f\"Accuracy XGBoost: {accuracy_score(train['xgb'].values, y_true)}\")\n",
    "print(f\"Accuracy LightGBM: {accuracy_score(train['lgm'].values, y_true)}\")\n",
    "print(f\"Accuracy Catboost: {accuracy_score(train['cb'].values, y_true)}\")\n",
    "print(f\"Accuracy Vopal Wabbit: {accuracy_score(train['vw'].values, y_true)}\")\n",
    "print(f\"Accuracy SGD: {accuracy_score(train['sgd'].values, y_true)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9990df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
